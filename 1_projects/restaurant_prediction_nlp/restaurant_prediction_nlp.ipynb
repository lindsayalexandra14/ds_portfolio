{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lindsayalexandra14/ds_portfolio/blob/main/1_projects/restaurant_prediction_nlp/restaurant_prediction_nlp.ipynb)\n"
      ],
      "metadata": {
        "id": "tEf00TXP4MDD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4puKf9eiLnc9",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# !pip install pipreqs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJEO0jsn_gWf"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import gensim\n",
        "except ImportError:\n",
        "    !pip install gensim\n",
        "    import gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w30mWXh0_2n7"
      },
      "source": [
        "ðŸ“¦ This notebook requires `gensim`.  \n",
        "Run the install cell above first. If Colab asks you to restart the runtime, do that, then re-run the notebook from the top.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Restaurant%20Type%20Prediction%20NLP.png)"
      ],
      "metadata": {
        "id": "OOGjG96RJdNZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Introduction.png)"
      ],
      "metadata": {
        "id": "UISEYCsDc1Js"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZxZprIWkjBD"
      },
      "source": [
        "\n",
        "\n",
        "*  Author: Lindsay McFarlane\n",
        "*  Date: May 2025\n",
        "*  Objective: Predict restaurant type from restaurant data using any type of NLP model\n",
        "* Goal: Accuracy above ~76%, outperforming given baseline model\n",
        "* Result: 82% accuracy (vs. 76% baseline), an improvement of ~8 %+ over baseline\n",
        "* Data: 3rd party data (from UCSD NLP Class) on restaurant reviews & other restaurant features\n",
        "* Models:\n",
        "\n",
        "    1.   Avg. word embeddings of restaurant reviews (baseline)\n",
        "    2.   Avg. Word Embeddings (review + features)\n",
        "    3.   BERT Transformer (on reviews)\n",
        "    4.   BERT Transformer on reviews + features\n",
        "    5.   RoBERTA Transformer on reviews & features\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "toc",
        "id": "FZD6_ekBkY3N"
      },
      "source": [
        ">>[Import Data](#scrollTo=Rhq9-i6WaWOO)\n",
        "\n",
        ">>[View Data](#scrollTo=yOWoCaNkYtS-)\n",
        "\n",
        ">[Data Preparation](#scrollTo=cK4PnORqYp5Y)\n",
        "\n",
        ">[Initial Dimension Reduction](#scrollTo=WAD9194iRmst)\n",
        "\n",
        ">[EDA](#scrollTo=K6D3CQoVZGPb)\n",
        "\n",
        ">[Dimension Reduction](#scrollTo=sNI3285xZLw3)\n",
        "\n",
        ">[Average Embedding Models](#scrollTo=h99-Cxve7Bv3)\n",
        "\n",
        ">>[Data Pre-Processing](#scrollTo=BQrAAU1a1J3b)\n",
        "\n",
        ">>[Model 1](#scrollTo=ir7d2aDE6Nk0)\n",
        "\n",
        ">>[Model 2](#scrollTo=sfRa7_EW6Bw6)\n",
        "\n",
        ">[BERT Transformer Models](#scrollTo=dmyCqwti0l9y)\n",
        "\n",
        ">>[Model 3](#scrollTo=LRmbbe9-NRXH)\n",
        "\n",
        ">>[Model 4](#scrollTo=JL5WNzgt2sP8)\n",
        "\n",
        ">[RoBERTa Transformer Model](#scrollTo=_VUOlEPd0uiM)\n",
        "\n",
        ">>[Model 5](#scrollTo=qy-UWADF18FP)\n",
        "\n",
        ">[Model Comparison](#scrollTo=NSljNK9KRc7i)\n",
        "\n",
        ">[Misc](#scrollTo=oFuYjg7IPH64)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/tl;dr.png)"
      ],
      "metadata": {
        "id": "RRzL_tcYLNBm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project predicts restaurant type from restaurant reviews OR restaurant reviews + other restaurant features using the following models. This was the final performance:"
      ],
      "metadata": {
        "id": "FZ3SBDr5mo0m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "INPUT CODE FOR CHARTS IMAGE"
      ],
      "metadata": {
        "id": "UyvC_o50m_UH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rhq9-i6WaWOO"
      },
      "source": [
        "##Import Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Import%20Data.png)"
      ],
      "metadata": {
        "id": "cmQHgO1uc5OF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://raw.githubusercontent.com/lindsayalexandra14/ds_portfolio/refs/heads/main/1_projects/restaurant_prediction_nlp/train.csv\"\n",
        "!wget \"https://raw.githubusercontent.com/lindsayalexandra14/ds_portfolio/refs/heads/main/1_projects/restaurant_prediction_nlp/test.csv\"\n"
      ],
      "metadata": {
        "id": "3FQx-GCHrbLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIUjnc6qo_fe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df_train = pd.read_csv(\"train.csv\")\n",
        "df_test = pd.read_csv(\"test.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOWoCaNkYtS-"
      },
      "source": [
        "##View Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/View%20Data.png)"
      ],
      "metadata": {
        "id": "wtcJZfONdAm0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf8IOtj5d3Tf"
      },
      "source": [
        "View shape of data:\n",
        "\n",
        "*   13k rows and 62 features for training data\n",
        "*   10k rows and 61 features for test data (same features but does not have 'label' > one fewer feature)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6jh8e-spCQr"
      },
      "outputs": [],
      "source": [
        "print(df_train.shape)\n",
        "print(df_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Note: The given \"test set\" is unlabeled so won't be used here and was only used for Kaggle scoring in the platform*"
      ],
      "metadata": {
        "id": "rZC3cIFoEeW7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jObgAEI9qTiS"
      },
      "source": [
        "View names of all features/columns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMxKDH4CqpHR"
      },
      "outputs": [],
      "source": [
        "print(df_train. columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cK4PnORqYp5Y"
      },
      "source": [
        "#Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Data%20Preparation.png)"
      ],
      "metadata": {
        "id": "exC4POEIdEHl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Missing%20Values.png)"
      ],
      "metadata": {
        "id": "b8h71Lz3dGaH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W52WTTQLp7q-"
      },
      "source": [
        "Create dataframe of features with their count and % of missing values (if above 0 -> they had missing values):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgNiipHKphgj"
      },
      "outputs": [],
      "source": [
        "missing_df = pd.DataFrame({\n",
        "    'Missing Count': df_train.isnull().sum(),\n",
        "    'Missing %': (df_train.isnull().sum() / len(df_train)) * 100\n",
        "})\n",
        "missing_df[missing_df['Missing Count'] > 0].sort_values('Missing %', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foBCZopyqa6t"
      },
      "source": [
        " Drop columns with more than 70% missing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRN91TU8KV9x"
      },
      "outputs": [],
      "source": [
        "# Threshold to keep columns with at least 30% non-null values\n",
        "threshold = 0.30\n",
        "\n",
        "original_cols = df_train.columns\n",
        "\n",
        "valid_cols = df_train.columns[df_train.isnull().mean() < (1 - threshold)]\n",
        "\n",
        "# Except keep the bitcoin feature despite its missingness %\n",
        "if \"attributes.BusinessAcceptsBitcoin\" in df_train.columns and \\\n",
        "   \"attributes.BusinessAcceptsBitcoin\" not in valid_cols:\n",
        "    valid_cols = valid_cols.append(pd.Index([\"attributes.BusinessAcceptsBitcoin\"]))\n",
        "\n",
        "# Drop columns in original_cols but NOT in valid_cols\n",
        "dropped_cols = original_cols.difference(valid_cols)\n",
        "\n",
        "print(f\"Columns dropped ({len(dropped_cols)}):\")\n",
        "print(dropped_cols.tolist())\n",
        "\n",
        "# Set dataframes to only include valid columns for training and test\n",
        "df_train = df_train[valid_cols]\n",
        "df_test = df_test[valid_cols.intersection(df_test.columns)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "View updated data shape and features:"
      ],
      "metadata": {
        "id": "rqJ2SdFuIusQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spl71CZPppXX"
      },
      "outputs": [],
      "source": [
        "print(df_train.shape)\n",
        "print(df_test.shape)\n",
        "print(df_train.columns)\n",
        "print(df_test.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Removing%20Characters.png)"
      ],
      "metadata": {
        "id": "De_w2eaWdNan"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOaOUKfD2Tgm"
      },
      "source": [
        "View state of formatting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9Wd-xX90Q1A"
      },
      "outputs": [],
      "source": [
        "print(df_train.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfSX_ZefzatJ"
      },
      "source": [
        "Fix string formatting, first combining the training and test to apply formatting to both datasets at once. Then remove byte-string (b'), unicode-string (u'), and quote characters from the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiVFsFp-sas6"
      },
      "outputs": [],
      "source": [
        "df_train[\"source\"] = \"train\"\n",
        "df_test[\"source\"] = \"test\"\n",
        "combined = pd.concat([df_train, df_test], axis=0)\n",
        "\n",
        "combined = combined.apply(lambda col: col.astype(str).str.replace(r\"^b'|^b\\\"|\\\"|'|u'\", '', regex=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evfT2Ryfzy1M"
      },
      "source": [
        "Split data back into training and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPfCheoUtqXs"
      },
      "outputs": [],
      "source": [
        "df_train = combined[combined[\"source\"] == \"train\"].drop(\"source\", axis=1)\n",
        "df_test = combined[combined[\"source\"] == \"test\"].drop(\"source\", axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRciqkiq0Exn"
      },
      "source": [
        "View data to check that characters were removed and formatting looks usable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8DgI0MHtuoJ"
      },
      "outputs": [],
      "source": [
        "print(df_train.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5bak-3Y_TX0"
      },
      "source": [
        "Note, the combining and separating the train and test sets above gave a 'label' column to the test set, just with na's. Won't be pulled in later, but good to know:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "doZWTwSv_Fcw"
      },
      "outputs": [],
      "source": [
        "print(df_test['label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Handle%20Null%20Values.png)"
      ],
      "metadata": {
        "id": "AVWILftddRi_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-x3xEr32fo-"
      },
      "source": [
        "Make 'None's in a consistent format:\n",
        "Replace actual NaNs with the string 'None'.\n",
        "Normalize anything that *means* 'None' (case-insensitive):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnvxrBlxuMaz"
      },
      "outputs": [],
      "source": [
        "df_train = df_train.fillna('None')\n",
        "df_train = df_train.applymap(lambda x: 'None' if str(x).strip().lower() in ['none', 'nan', 'b\\'none\\'', 'b\"none\"'] else x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIZnC00q3T6Y"
      },
      "source": [
        "Apply same formatting to the test data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27nSWn0WuVqZ"
      },
      "outputs": [],
      "source": [
        "df_test = df_test.fillna('None')\n",
        "\n",
        "df_test = df_test.applymap(lambda x: 'None' if str(x).strip().lower() in ['none', 'nan', 'b\\'none\\'', 'b\"none\"'] else x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initial Dimension Reduction"
      ],
      "metadata": {
        "id": "WAD9194iRmst"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Initial%20Dimension%20Reduction.png)"
      ],
      "metadata": {
        "id": "xCdhPw4ydVvH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop features:\n",
        "\n",
        "*   id, business_id - not informative\n",
        "*   latitude, longitude, address, postal code, city, hours - too granular to use\n",
        "*   is_open, review count - not indicative of type\n",
        "*  parking (bike, business) - not indicative of type, one field is too complex for low value, mostly dependent on the city/location\n",
        "*   attributes is a field of all the attributes combined - don't want all\n"
      ],
      "metadata": {
        "id": "PhHM3oP5ZZsR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop columns that will definitely not be used:"
      ],
      "metadata": {
        "id": "QyX8IPt9JdwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop = ['id','business_id','latitude','longitude','hours','address', 'postal_code','city',\n",
        "                   'hours.Monday','hours.Tuesday','hours.Wednesday','hours.Thursday',\n",
        "                   'hours.Friday','hours.Saturday', 'hours.Sunday',\n",
        "                   'attributes.BusinessParking','attributes.BikeParking',\n",
        "                   'is_open','review_count','attributes']\n",
        "df_train = df_train.drop(columns_to_drop, axis=1)\n",
        "df_test= df_test.drop(columns_to_drop, axis=1)"
      ],
      "metadata": {
        "id": "u8SBInSfJk2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train.columns)"
      ],
      "metadata": {
        "id": "YovdqAd0WDrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Feature%20Engineering.png)"
      ],
      "metadata": {
        "id": "zj142nn4dao_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The feature engineering that I performed is largely to provide as much concise, text-rich info as possible phrased in a Natural Language way that BERT would interpret better than for example: \"AZ\" (for a state) or \"PriceRange: 2\" which were their original form."
      ],
      "metadata": {
        "id": "LR5WYOVMT9nV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note, first relabeling the review field to \"text\" as it's more intuitive and standard as an input feature name for the NLP tokenizing functions. Then the \"review\" field is included as a field to drop:"
      ],
      "metadata": {
        "id": "1uGcXsQU-FgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[\"text\"] = df_train[\"review\"]\n",
        "df_test[\"text\"] = df_test[\"review\"]"
      ],
      "metadata": {
        "id": "lKGDsKKA90Vj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2nppMG3Atv_"
      },
      "source": [
        "I viewed the unique states in the 'state' column in order to build a state map to assign their exact state names to the values so that it has more specific/useful text information to feed the natural language processing model.\n",
        "\n",
        "This is important, for example, to identify the Candadian states (e.g., for 'Quebec Canada' the word 'Canada' can be picked up in the model and help predict the 'Canadian restaurant' type).\n",
        "\n",
        "There are other ways to group the data and assign regions to it but there were not that many states so I did not group them. Adding the full state names in the model though should provide clearer info for the word embeddings, in addition to adding the Canadian tag:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jz31GZbsyWsg"
      },
      "outputs": [],
      "source": [
        "print(df_train[\"state\"].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "in5HOAUOx_nz"
      },
      "outputs": [],
      "source": [
        "state_map = {\n",
        "    \"QC\": \"Quebec Canada\",\n",
        "    \"ON\": \"Ontario Canada\",\n",
        "    \"BC\": \"British Columbia Canada\",\n",
        "    \"AZ\": \"Arizona\",\n",
        "    \"OH\": \"Ohio\",\n",
        "    \"NV\": \"Nevada\",\n",
        "    \"SC\": \"South Carolina\",\n",
        "    \"WI\": \"Wisconsin\",\n",
        "    \"PA\": \"Philadelphia\",\n",
        "    \"NC\": \"North Carolina\",\n",
        "    \"IL\": \"Illinois\",\n",
        "    \"VA\": \"Virginia\",\n",
        "    \"AB\": \"Alberta Canada\"\n",
        "}\n",
        "\n",
        "df_train[\"state\"] = df_train[\"state\"].map(state_map).fillna(df_train[\"state\"])\n",
        "df_test[\"state\"] = df_test[\"state\"].map(state_map).fillna(df_test[\"state\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vlsNhReB6cG"
      },
      "source": [
        "Confirm mapping and show new 'state' values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRadaZBEy684"
      },
      "outputs": [],
      "source": [
        "print(df_train[\"state\"].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Gmu_gAj_yfY"
      },
      "source": [
        "Inspect 'attribute' columns and their unique values because they have the same complex structure. Some were True/False/None but some were dictionaries. They will need to be reformatted:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68ZGMlGtuaPn"
      },
      "outputs": [],
      "source": [
        "for col in df_train.columns:\n",
        "    if col.startswith(\"attributes.\"):\n",
        "        print(f\"\\nColumn: {col}\")\n",
        "        print(df_train[col].dropna().astype(str).unique().tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ZS4CafZTvjpc"
      },
      "outputs": [],
      "source": [
        "print(df_train.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUh_SSFSCEmP"
      },
      "source": [
        "I viewed the 'Attire' values and wanted to maintain the word \"attire\" for the model to read and only keep the values that have valuable text info so I reformatted and removed the 'None' values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuTJoM0jzDB5"
      },
      "outputs": [],
      "source": [
        "print(df_train[\"attributes.RestaurantsAttire\"].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTnyoO_Je1Y_"
      },
      "outputs": [],
      "source": [
        "def map_attire(value):\n",
        "    if value == \"casual\":\n",
        "        return \"Casual attire\"\n",
        "    elif value == \"dressy\":\n",
        "        return \"Dressy attire\"\n",
        "    elif value == \"formal\":\n",
        "        return \"Formal attire\"\n",
        "    else:\n",
        "        return \"\"  # For None or anything else\n",
        "\n",
        "df_train[\"attributes.RestaurantsAttire\"] = df_train[\"attributes.RestaurantsAttire\"].apply(map_attire)\n",
        "df_test[\"attributes.RestaurantsAttire\"] = df_test[\"attributes.RestaurantsAttire\"].apply(map_attire)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voqGUgdC9mzd"
      },
      "source": [
        "This \"no false\" version (not also adding \"Not Kid-Friendly\") performed better for these types of features where there was a True False, implying the negative versions are likely adding noise so my strategy was to only keep the positive values and make them as concise and word embedding friendly as possible. This way it was more likely to produce a cleaner signal for the words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErQkLCzzCVqL"
      },
      "source": [
        "Similarly I adjusted the \"Good for Kids\" field to \"Kid-friendly so that the text information is again in the values instead of just saying True False and also so it is concise enough to be well-interpreted by the word embeddings in the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuhpwA2gUeO1"
      },
      "outputs": [],
      "source": [
        "def map_wifi(value):\n",
        "    if value == \"free\":\n",
        "        return \"Free WiFi\"\n",
        "        #['no', 'None', 'free', 'paid']\n",
        "    elif value == \"paid\":\n",
        "        return \"Paid WiFi\"\n",
        "    else:\n",
        "        return \"\"  # For None or anything else\n",
        "\n",
        "df_train[\"attributes.WiFi\"] = df_train[\"attributes.WiFi\"].apply(map_wifi)\n",
        "df_test[\"attributes.WiFi\"] = df_test[\"attributes.WiFi\"].apply(map_wifi)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpAMbhY7Ueu6"
      },
      "outputs": [],
      "source": [
        "def map_noise(value):\n",
        "    if value == \"loud\":\n",
        "        return \"Noisy\"\n",
        "    elif value == \"quiet\":\n",
        "        return \"Quiet\"\n",
        "    elif value == \"average\":\n",
        "        return \"Average noise\"\n",
        "    elif value == \"very_loud\":\n",
        "        return \"Very noisy\"\n",
        "    else:\n",
        "        return \"\"  # For None or anything else\n",
        "        #['loud', 'quiet', 'None', 'average', 'very_loud']\n",
        "\n",
        "df_train[\"attributes.NoiseLevel\"] = df_train[\"attributes.NoiseLevel\"].apply(map_noise)\n",
        "df_test[\"attributes.NoiseLevel\"] = df_test[\"attributes.NoiseLevel\"].apply(map_noise)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_roHxKODdwj"
      },
      "outputs": [],
      "source": [
        "def map_good_for_kids(value):\n",
        "    if value is True or value == \"True\":\n",
        "        return \"Kid-friendly\"\n",
        "    elif value is False or value == \"False\":\n",
        "        return \"False\"\n",
        "    else:\n",
        "        return \"\"  # For None or anything else\n",
        "\n",
        "df_train[\"attributes.GoodForKids\"] = df_train[\"attributes.GoodForKids\"].apply(map_good_for_kids)\n",
        "df_test[\"attributes.GoodForKids\"] = df_test[\"attributes.GoodForKids\"].apply(map_good_for_kids)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBbUFBXpEGC6"
      },
      "outputs": [],
      "source": [
        "print(df_train[\"attributes.GoodForKids\"].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-xuUyIqCoeL"
      },
      "source": [
        "I performed the same formatting adjustment on the fields below so that they also include as much text information as possible to feed the natural language model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ii4-FBkXk-TA"
      },
      "outputs": [],
      "source": [
        "def map_delivery(value):\n",
        "    if value is True or value == \"True\":\n",
        "        return \"Delivery\"\n",
        "    elif value is False or value == \"False\":\n",
        "        return \"False\"\n",
        "    else:\n",
        "        return \"\"  # For None or anything else\n",
        "\n",
        "df_train[\"attributes.RestaurantsDelivery\"] = df_train[\"attributes.RestaurantsDelivery\"].apply(map_delivery)\n",
        "df_test[\"attributes.RestaurantsDelivery\"] = df_test[\"attributes.RestaurantsDelivery\"].apply(map_delivery)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkVs82zBcxjj"
      },
      "source": [
        " For 'Price' I gave them low, medium, high, very high price for the same reason:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fjIQ8RtKccD"
      },
      "outputs": [],
      "source": [
        "print(df_train[\"attributes.RestaurantsPriceRange2\"].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHCUDOh1Ls3D"
      },
      "outputs": [],
      "source": [
        "def map_pricerange(value):\n",
        "    if value =='1':\n",
        "        return \"Low Price\"\n",
        "    elif value =='2':\n",
        "        return \"Moderate Price\"\n",
        "    elif value =='3':\n",
        "        return \"High Price\"\n",
        "    elif value =='4':\n",
        "        return \"Very High Price\"\n",
        "    else:\n",
        "        return \"\"  # For None or anything else\n",
        "\n",
        "df_train[\"attributes.RestaurantsPriceRange2\"] = df_train[\"attributes.RestaurantsPriceRange2\"].apply(map_pricerange)\n",
        "df_test[\"attributes.RestaurantsPriceRange2\"] = df_test[\"attributes.RestaurantsPriceRange2\"].apply(map_pricerange)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfU21A5nIYfB"
      },
      "outputs": [],
      "source": [
        "print(df_train['attributes.RestaurantsPriceRange2'].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlTOZTG7uKg6"
      },
      "outputs": [],
      "source": [
        "def map_cc(value):\n",
        "    if value is True or value == \"True\":\n",
        "        return \"Accepts Credit Cards\"\n",
        "    elif value is False or value == \"False\":\n",
        "        return \"False\"\n",
        "    else:\n",
        "        return \"\"  # For None or anything else\n",
        "\n",
        "df_train[\"attributes.BusinessAcceptsCreditCards\"] = df_train[\"attributes.BusinessAcceptsCreditCards\"].apply(map_cc)\n",
        "df_test[\"attributes.BusinessAcceptsCreditCards\"] = df_test[\"attributes.BusinessAcceptsCreditCards\"].apply(map_cc)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def map_bitcoin(value):\n",
        "    if value is True or value == \"True\":\n",
        "        return \"Accepts Bitcoin\"\n",
        "    elif value is False or value == \"False\":\n",
        "        return \"False\"\n",
        "    else:\n",
        "        return \"\"  # For None or anything else\n",
        "\n",
        "df_train[\"attributes.BusinessAcceptsBitcoin\"] = df_train[\"attributes.BusinessAcceptsBitcoin\"].apply(map_bitcoin)\n",
        "df_test[\"attributes.BusinessAcceptsBitcoin\"] = df_test[\"attributes.BusinessAcceptsBitcoin\"].apply(map_bitcoin)\n"
      ],
      "metadata": {
        "id": "0mGNpJgTJ1FU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjHI3KnBuan4"
      },
      "outputs": [],
      "source": [
        "def map_outdoor_seating(value):\n",
        "    if value is True or value == \"True\":\n",
        "        return \"Outdoor Seating\"\n",
        "    elif value is False or value == \"False\":\n",
        "        return \"False\"\n",
        "    else:\n",
        "        return \"\"  # For None or anything else\n",
        "\n",
        "df_train[\"attributes.OutdoorSeating\"] = df_train[\"attributes.OutdoorSeating\"].apply(map_outdoor_seating)\n",
        "df_test[\"attributes.OutdoorSeating\"] = df_test[\"attributes.OutdoorSeating\"].apply(map_outdoor_seating)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def map_tv(value):\n",
        "    if value is True or value == \"True\":\n",
        "        return \"Has TV\"\n",
        "    elif value is False or value == \"False\":\n",
        "        return \"False\"\n",
        "    else:\n",
        "        return \"\"  # For None or anything else\n",
        "\n",
        "df_train[\"attributes.HasTV\"] = df_train[\"attributes.HasTV\"].apply(map_tv)\n",
        "df_test[\"attributes.HasTV\"] = df_test[\"attributes.HasTV\"].apply(map_tv)\n"
      ],
      "metadata": {
        "id": "EaAq_7C2HmnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_groups(value):\n",
        "    if value is True or value == \"True\":\n",
        "        return \"Good for Groups\"\n",
        "    elif value is False or value == \"False\":\n",
        "        return \"False\"\n",
        "    else:\n",
        "        return \"\"  # For None or anything else\n",
        "\n",
        "df_train[\"attributes.RestaurantsGoodForGroups\"] = df_train[\"attributes.RestaurantsGoodForGroups\"].apply(map_groups)\n",
        "df_test[\"attributes.RestaurantsGoodForGroups\"] = df_test[\"attributes.RestaurantsGoodForGroups\"].apply(map_groups)\n"
      ],
      "metadata": {
        "id": "5pYH0VF9HvpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_tableservice(value):\n",
        "    if value is True or value == \"True\":\n",
        "        return \"Table Service\"\n",
        "    elif value is False or value == \"False\":\n",
        "        return \"False\"\n",
        "    else:\n",
        "        return \"\"  # For None or anything else\n",
        "\n",
        "df_train[\"attributes.RestaurantsTableService\"] = df_train[\"attributes.RestaurantsTableService\"].apply(map_tableservice)\n",
        "df_test[\"attributes.RestaurantsTableService\"] = df_test[\"attributes.RestaurantsTableService\"].apply(map_tableservice)\n"
      ],
      "metadata": {
        "id": "EBLlWZ70IpPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6XnZLH2MNMn"
      },
      "outputs": [],
      "source": [
        "def map_reservations(value):\n",
        "    if value is True or value == \"True\":\n",
        "        return \"Takes reservations\"\n",
        "    elif value is False or value == \"False\":\n",
        "        return \"False\"\n",
        "    else:\n",
        "        return \"\"  # For None or anything else\n",
        "\n",
        "df_train[\"attributes.RestaurantsReservations\"] = df_train[\"attributes.RestaurantsReservations\"].apply(map_reservations)\n",
        "df_test[\"attributes.RestaurantsReservations\"] = df_test[\"attributes.RestaurantsReservations\"].apply(map_reservations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQlRW1GXlT6N"
      },
      "outputs": [],
      "source": [
        "def map_takeout(value):\n",
        "    if value is True or value == \"True\":\n",
        "        return \"Takeout\"\n",
        "    elif value is False or value == \"False\":\n",
        "        return \"False\"\n",
        "    else:\n",
        "        return \"\"  # For None or anything else\n",
        "\n",
        "df_train[\"attributes.RestaurantsTakeOut\"] = df_train[\"attributes.RestaurantsTakeOut\"].apply(map_takeout)\n",
        "df_test[\"attributes.RestaurantsTakeOut\"] = df_test[\"attributes.RestaurantsTakeOut\"].apply(map_takeout)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def map_caters(value):\n",
        "    if value is True or value == \"True\":\n",
        "        return \"Caters\"\n",
        "    elif value is False or value == \"False\":\n",
        "        return \"False\"\n",
        "    else:\n",
        "        return \"\"  # For None or anything else\n",
        "\n",
        "df_train[\"attributes.Caters\"] = df_train[\"attributes.Caters\"].apply(map_caters)\n",
        "df_test[\"attributes.Caters\"] = df_test[\"attributes.Caters\"].apply(map_caters)\n"
      ],
      "metadata": {
        "id": "bm6pl0gQG81f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_alcohol(value):\n",
        "    if value == \"beer_and_wine\":\n",
        "        return \"Beer and Wine\"\n",
        "    elif value == \"full_bar\":\n",
        "        return \"Full bar\"\n",
        "    else:\n",
        "        return \"\"  # For None or anything else\n",
        "\n",
        "df_train[\"attributes.Alcohol\"] = df_train[\"attributes.Alcohol\"].apply(map_alcohol)\n",
        "df_test[\"attributes.Alcohol\"] = df_test[\"attributes.Alcohol\"].apply(map_alcohol)\n"
      ],
      "metadata": {
        "id": "qPZbOvNy-FaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35xa_tAkXKwt"
      },
      "outputs": [],
      "source": [
        "type(df_train[\"attributes.GoodForMeal\"].iloc[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ-e6zmuQ9pp"
      },
      "source": [
        "'Good for Meal' and 'Ambience' had the string dictionary-type structure that needed major reformatting to parse out Ambience: casual: True, romantic: False for example to just 'casual'. Or 'Good for Dinner vs. 'Breakfast: False, Dinner: True, etc. This removes unnecessary words where things are False since the model can only take in so many words.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3RjwDJxXPR3"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "\n",
        "# Step 1: Convert the string into a usable dictionary\n",
        "def parse_good_for_meal(row):\n",
        "    if not isinstance(row, str) or row.strip() == \"\":\n",
        "        return {}\n",
        "    try:\n",
        "        # Add quotes around keys and convert True/False to JSON compatible format\n",
        "        fixed = re.sub(r'(\\w+):', r'\"\\1\":', row)  # keys\n",
        "        fixed = fixed.replace(\"True\", \"true\").replace(\"False\", \"false\")  # booleans\n",
        "        return json.loads(fixed)\n",
        "    except Exception as e:\n",
        "        # print(f\"Failed to parse: {row}\")\n",
        "        return {}\n",
        "\n",
        "# Step 2: Create readable label from True values\n",
        "def label_good_meals(meal_dict):\n",
        "    return ', '.join([f\"Good for {k}\" for k, v in meal_dict.items() if v is True])\n",
        "\n",
        "# Step 3: Apply both steps\n",
        "df_train[\"GoodForMeal_dict\"] = df_train[\"attributes.GoodForMeal\"].apply(parse_good_for_meal)\n",
        "df_train[\"attributes.GoodForMeal\"] = df_train[\"GoodForMeal_dict\"].apply(label_good_meals)\n",
        "\n",
        "df_test[\"GoodForMeal_dict\"] = df_test[\"attributes.GoodForMeal\"].apply(parse_good_for_meal)\n",
        "df_test[\"attributes.GoodForMeal\"] = df_test[\"GoodForMeal_dict\"].apply(label_good_meals)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mvwm9VInZA8N"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "\n",
        "# Step 1: Convert the string into a usable dictionary\n",
        "def parse_ambience(row):\n",
        "    if not isinstance(row, str) or row.strip() == \"\":\n",
        "        return {}\n",
        "    try:\n",
        "        # Add quotes around keys and convert True/False to JSON compatible format\n",
        "        fixed = re.sub(r'(\\w+):', r'\"\\1\":', row)  # keys\n",
        "        fixed = fixed.replace(\"True\", \"true\").replace(\"False\", \"false\")  # booleans\n",
        "        return json.loads(fixed)\n",
        "    except Exception as e:\n",
        "        # print(f\"Failed to parse: {row}\")\n",
        "        return {}\n",
        "\n",
        "# Step 2: Create readable label from True values\n",
        "def label_ambience(ambience_dict):\n",
        "    return ', '.join([f\"{k}\" for k, v in ambience_dict.items() if v is True])\n",
        "\n",
        "# Step 3: Apply both steps\n",
        "df_train[\"Ambience_dict\"] = df_train[\"attributes.Ambience\"].apply(parse_ambience)\n",
        "df_train[\"attributes.Ambience\"] = df_train[\"Ambience_dict\"].apply(label_ambience)\n",
        "\n",
        "df_test[\"Ambience_dict\"] = df_test[\"attributes.Ambience\"].apply(parse_ambience)\n",
        "df_test[\"attributes.Ambience\"] = df_test[\"Ambience_dict\"].apply(label_ambience)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzHlUrEkON4O"
      },
      "outputs": [],
      "source": [
        "df_train.drop([\"GoodForMeal_dict\", \"Ambience_dict\"], axis=1, inplace=True)\n",
        "df_test.drop([\"GoodForMeal_dict\", \"Ambience_dict\"], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check examples for Good For Meal and Ambience. They have many unique values, so checking them this way vs. the ones with few unique values below it:"
      ],
      "metadata": {
        "id": "9NVOhpfWLOPi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiKUHmjmO18W"
      },
      "outputs": [],
      "source": [
        "print(df_train[\"attributes.GoodForMeal\"].head(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUm_PFXfMKRC"
      },
      "outputs": [],
      "source": [
        "print(df_train[\"attributes.Ambience\"].head(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check new unique values for attribute features:"
      ],
      "metadata": {
        "id": "GA-VFXErLIMz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WAiC3kBO42w"
      },
      "outputs": [],
      "source": [
        "for col in df_train.columns:\n",
        "    if col.startswith(\"attributes.\") and col not in [\"attributes.GoodForMeal\", \"attributes.Ambience\"]:\n",
        "        print(f\"\\nColumn: {col}\")\n",
        "        print(df_train[col].dropna().astype(str).unique().tolist())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntg7RGGSTSGj"
      },
      "source": [
        "Although some restaurant-specific features were too specific or not useful to input into the model, the 'name' I hypothesized would be very important. The words in a restaurant name whether they are French (to indicate Canadian) or include something related to the restaurant type ('Tacos') really help add information to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvppLYB7TM5A"
      },
      "outputs": [],
      "source": [
        "print(df_train['name'].head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EDA"
      ],
      "metadata": {
        "id": "K6D3CQoVZGPb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/EDA.png)"
      ],
      "metadata": {
        "id": "8htocC-Ndh1v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Bar%20Plots.png)"
      ],
      "metadata": {
        "id": "9leMoHtMdj6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a custom color palette\n",
        "custom_palette = [\n",
        "    '#8dd3c7',\n",
        "    '#bebada',\n",
        "    '#ab8072',\n",
        "    '#80b1d3',\n",
        "    '#fdb462',\n",
        "    '#b3de69',\n",
        "    '#fccde5',\n",
        "    '#d9d9d9',\n",
        "    '#bc80bd',\n",
        "    '#17becf',\n",
        "    '#aec7e8',\n",
        "    '#bbb005']\n",
        "\n",
        "sns.palplot(custom_palette)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9bLZX-pJ8NKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function for creating bar plots of Features (Restaurant Features) vs. Labels (Restaurant Type):"
      ],
      "metadata": {
        "id": "6CV6kanRPGE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "label_col = 'label'\n",
        "feature_cols = [\n",
        "    'attributes.OutdoorSeating',\n",
        "    'attributes.BusinessAcceptsCreditCards',\n",
        "    'attributes.RestaurantsTableService',\n",
        "    'attributes.RestaurantsReservations',\n",
        "    'attributes.RestaurantsPriceRange2',\n",
        "    'attributes.WiFi',\n",
        "    'attributes.NoiseLevel',\n",
        "    'state',\n",
        "    'attributes.Alcohol',\n",
        "    'attributes.HasTV',\n",
        "    'attributes.RestaurantsGoodForGroups',\n",
        "    'attributes.Caters',\n",
        "    'attributes.RestaurantsTakeOut',\n",
        "    'attributes.RestaurantsAttire',\n",
        "    'attributes.RestaurantsDelivery',\n",
        "    'attributes.GoodForKids',\n",
        "    'attributes.BusinessAcceptsBitcoin'\n",
        "]\n",
        "\n",
        "# In case want to view unknowns\n",
        "df_plot = df_train.copy()\n",
        "df_plot[feature_cols] = df_plot[feature_cols].replace('', 'Unknown').fillna(\"Unknown\")\n",
        "df_plot[label_col] = df_plot[label_col].replace('', 'Unknown').fillna(\"Unknown\")\n",
        "\n",
        "# Plotting function\n",
        "def plot_categorical_barplots(\n",
        "    data,\n",
        "    features,\n",
        "    x_axis='feature',\n",
        "    hue_axis='label',\n",
        "    percentage=False,\n",
        "    drop_unknown=False,\n",
        "    title_suffix=\"\"\n",
        "):\n",
        "    n_cols = 3\n",
        "    n_rows = -(-len(features) // n_cols)  # ceiling division\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 5 * n_rows))\n",
        "    axes = axes.flatten()\n",
        "    custom_palette = [\n",
        "    '#8dd3c7',\n",
        "    '#bebada',\n",
        "    '#ab8072',\n",
        "    '#80b1d3',\n",
        "    '#fdb462',\n",
        "    '#b3de69',\n",
        "    '#fccde5',\n",
        "    '#d9d9d9',\n",
        "    '#bc80bd',\n",
        "    '#17becf',\n",
        "    '#aec7e8',\n",
        "    '#bbb005']\n",
        "\n",
        "# sns.palplot(custom_palette)\n",
        "# plt.show()\n",
        "\n",
        "    for i, col in enumerate(features):\n",
        "        ax = axes[i]\n",
        "\n",
        "        x_col = col if x_axis == 'feature' else label_col\n",
        "        hue_col = label_col if x_axis == 'feature' else col\n",
        "\n",
        "        plot_data = data.copy()\n",
        "        if drop_unknown:\n",
        "            plot_data = plot_data[\n",
        "                (plot_data[x_col] != 'Unknown') & (plot_data[hue_col] != 'Unknown')\n",
        "            ]\n",
        "\n",
        "        # Build custom palette\n",
        "        unique_values = plot_data[hue_col].unique()\n",
        "        has_false = 'False' in unique_values\n",
        "\n",
        "        if has_false:\n",
        "            palette = {'False': 'gray'} #gray for Falses\n",
        "            other_values = sorted([val for val in unique_values if val != 'False'])\n",
        "            other_colors = sns.color_palette('Set2', len(other_values))\n",
        "            palette.update({val: color for val, color in zip(other_values, other_colors)})\n",
        "\n",
        "        else: #custom palette\n",
        "            other_values = sorted(unique_values)\n",
        "            if len(other_values) > len(custom_palette):\n",
        "                raise ValueError(\"Not enough colors in custom_palette for the number of unique values.\")\n",
        "            palette = {val: custom_palette[i] for i, val in enumerate(other_values)}\n",
        "\n",
        "\n",
        "        if percentage: #for % of total (vs. count)\n",
        "            count_df = plot_data.groupby([x_col, hue_col]).size().reset_index(name='count')\n",
        "            total_per_x = count_df.groupby(x_col)['count'].transform('sum')\n",
        "            count_df['percent'] = (count_df['count'] / total_per_x) * 100\n",
        "\n",
        "            sns.barplot(\n",
        "                data=count_df,\n",
        "                x=x_col,\n",
        "                y='percent',\n",
        "                hue=hue_col,\n",
        "                palette=palette,\n",
        "                ax=ax\n",
        "            )\n",
        "            ax.set_ylabel('Percent (%)')\n",
        "        else: # by raw counts\n",
        "            sns.countplot(\n",
        "                data=plot_data,\n",
        "                x=x_col,\n",
        "                hue=hue_col,\n",
        "                palette=palette,\n",
        "                ax=ax\n",
        "            )\n",
        "            ax.set_ylabel('Count')\n",
        "\n",
        "        ax.set_title(f\"{col.replace('attributes.', '').replace('_', ' ')} {title_suffix}\", fontsize=11)\n",
        "        ax.set_xlabel('')\n",
        "        ax.tick_params(axis='x', rotation=30)\n",
        "        ax.legend(title=hue_col, fontsize=8)\n",
        "\n",
        "    # Remove unused subplots\n",
        "    for j in range(i + 1, len(axes)):\n",
        "        fig.delaxes(axes[j])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "5TPEr4Ii_PRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar Plots by Feature color-coded by Label in term of raw counts to see volume:"
      ],
      "metadata": {
        "id": "PiZmJzf8PPG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Count\n",
        "plot_categorical_barplots(\n",
        "    df_plot,\n",
        "    features=feature_cols,\n",
        "    x_axis='label',\n",
        "    hue_axis='feature',\n",
        "    percentage=False,\n",
        "    # palette=\"Set2\",\n",
        "    drop_unknown=True,\n",
        "    title_suffix='(Feature)'\n",
        ")"
      ],
      "metadata": {
        "id": "NT4RnGXJ1o1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar Plots by Feature and Label in terms of % of Total:"
      ],
      "metadata": {
        "id": "LJAAi_-cPUKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Percent of Total (excluding unknowns)\n",
        "plot_categorical_barplots(\n",
        "    df_plot,\n",
        "    features=feature_cols,\n",
        "    x_axis='label',\n",
        "    hue_axis='feature',\n",
        "    percentage=True,\n",
        "    # palette=\"Set2\",\n",
        "    drop_unknown=True,\n",
        "    title_suffix='(Feature % of Total)'\n",
        ")"
      ],
      "metadata": {
        "id": "G5-_SqnPMKI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Chi-Squared%20Tests.png)"
      ],
      "metadata": {
        "id": "215XkVredrHK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform chi-squared to isolate most relvant features in predicting Restaurant Type. This isn't an exact science because NLP uses word embeddings and the words of the feature are important in relation to other words, not in isolation, so this just to get some good guesses at what might help to include:"
      ],
      "metadata": {
        "id": "bplZVnT-Pk23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make a copy of the dataframe for the chi-squared to make sure to keep df_train intact:"
      ],
      "metadata": {
        "id": "9PiA3Xw0QCRZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6Znl8on3dui"
      },
      "outputs": [],
      "source": [
        "df_train_chi=df_train.copy()\n",
        "df_train_chi.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ambience, Business Parking, Name, and Good For Meal would be too lengthy to convert to dummies, so making a new df for the chi-squared that excludes those and converting to dummies on the other features:"
      ],
      "metadata": {
        "id": "dsjtfACOKgyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_chi = df_train.drop(['attributes.Ambience','name', 'review', 'text', 'attributes.GoodForMeal'], axis=1)"
      ],
      "metadata": {
        "id": "SNfVhLyuKtDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAbHtyLdGny4"
      },
      "source": [
        "Make dummy variables for chi squared:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyD0Wb727HME"
      },
      "outputs": [],
      "source": [
        "# Select only object (string-like) columns\n",
        "space_cols = [\n",
        "    col for col in df_train_chi.columns\n",
        "    if (col.startswith(\"attributes.\") or col.startswith(\"state\")) and col != 'label']\n",
        "\n",
        "# Make dummies for chi squared\n",
        "df_train_chi = pd.get_dummies(df_train_chi, columns=space_cols, dummy_na=False)\n",
        "\n",
        "# Clean up naming\n",
        "df_train_chi.columns = df_train_chi.columns.str.strip().str.replace(\"attributes.\", \"\", regex=False)\n",
        "df_train_chi.columns = df_train_chi.columns.str.replace('2_', '', regex=False)\n",
        "\n",
        "print(df_train_chi.columns)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run chi-squared test of features vs. label as a whole:\n",
        "\n",
        "For each feature, it tests whether the distribution of that feature differs across all classes (i.e., is dependent on the label).\n",
        "\n",
        "High chi-squared -> feature distribution is very different across labels â†’ good at distinguishing between multiple classes."
      ],
      "metadata": {
        "id": "YuIKMKVmh9aO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Ensure X and y are set correctly\n",
        "X_chi = df_train_chi.drop('label', axis=1).values  # Feature matrix\n",
        "y_chi = df_train_chi['label'].values               # Target labels\n",
        "\n",
        "# If y is not already numeric, encode it\n",
        "le = LabelEncoder()\n",
        "y_chi_encoded = le.fit_transform(y_chi)\n",
        "\n",
        "# Run Chi-squared test\n",
        "chi2_stats, p_values = chi2(X_chi, y_chi_encoded)\n",
        "\n",
        "# Create a DataFrame of results\n",
        "feature_names = df_train_chi.drop('label', axis=1).columns\n",
        "chi2_df = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'chi2_stat': chi2_stats,\n",
        "    'p_value': p_values\n",
        "})\n",
        "\n",
        "# Sort by chi2_stat to get top features\n",
        "chi2_df_sorted = chi2_df.sort_values(by='chi2_stat', ascending=False)\n",
        "print(chi2_df_sorted.head(20))  # Top 20 features overall\n"
      ],
      "metadata": {
        "id": "1pxcbnalg6CL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each class (Restaurant type) individually, tests whether the feature distinguishes that class vs all others (for optimization of individual class prediction if one or more in particular aren't performing well):"
      ],
      "metadata": {
        "id": "dYSa3o39iU0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "results_per_class = {}\n",
        "\n",
        "for class_label in np.unique(y_chi_encoded):\n",
        "    # Create binary target: 1 if current class, 0 otherwise\n",
        "    y_binary = (y_chi_encoded == class_label).astype(int)\n",
        "\n",
        "    chi2_stats, p_values = chi2(X_chi, y_binary)\n",
        "\n",
        "    results_df = pd.DataFrame({\n",
        "        'feature': feature_names,\n",
        "        'chi2_stat': chi2_stats,\n",
        "        'p_value': p_values\n",
        "    }).sort_values(by='chi2_stat', ascending=False)\n",
        "\n",
        "    results_per_class[le.inverse_transform([class_label])[0]] = results_df\n",
        "\n",
        "# Example: top 5 features for a specific class\n",
        "print(\"Top features for each class:\")\n",
        "for label in le.classes_:\n",
        "    print(f\"\\nTop features for class '{label}':\")\n",
        "    print(results_per_class[label].head(5))\n"
      ],
      "metadata": {
        "id": "vO9xj8KehFLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Build DataFrame (top N features per class)\n",
        "combined_rows = []\n",
        "top_n = 5\n",
        "\n",
        "for class_label in le.classes_:\n",
        "    top_features = results_per_class[class_label].head(top_n).copy()\n",
        "    top_features['class_label'] = class_label\n",
        "\n",
        "    # Add a unique ID to feature names to avoid duplicates\n",
        "    top_features['feature_display'] = top_features['feature'] + f\" ({class_label})\"\n",
        "\n",
        "    combined_rows.append(top_features)\n",
        "\n",
        "combined_df = pd.concat(combined_rows, ignore_index=True)\n",
        "\n",
        "# Plot using catplot\n",
        "g = sns.catplot(\n",
        "    data=combined_df,\n",
        "    x='chi2_stat',\n",
        "    y='feature',\n",
        "    col='class_label',\n",
        "    kind='bar',\n",
        "    col_wrap=2,\n",
        "    height=2,\n",
        "    aspect=3.5,\n",
        "    sharey=False,\n",
        "    color='#C8A2C8'\n",
        ")\n"
      ],
      "metadata": {
        "id": "oIabL7wKjAdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XuIKpJGM3WP9"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "palette=sns.diverging_palette(280, 40, s=70, l=50, n=20, as_cmap=False)\n",
        "sns.barplot(data=chi2_df_sorted.head(20), x='chi2_stat', y='feature',hue='feature', palette=palette, legend=False)\n",
        "\n",
        "\n",
        "plt.title('Top Features Associated with Label (Chi-Squared Test)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Finalize%20Data.png)"
      ],
      "metadata": {
        "id": "CWVpHK1asCA0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Edit: Filter out \"False\" for use in models:"
      ],
      "metadata": {
        "id": "ljV8I4_nkl3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df_train.columns:\n",
        "    if col.startswith(\"attributes.\") and col not in [\"attributes.GoodForMeal\", \"attributes.Ambience\"]:\n",
        "        print(f\"\\nColumn: {col}\")\n",
        "\n",
        "        # Replace string \"False\" with NaN\n",
        "        df_train[col] = df_train[col].replace(\"False\", pd.NA)\n",
        "\n",
        "        unique_vals = df_train[col].dropna().astype(str)\n",
        "        print(unique_vals.unique().tolist())\n"
      ],
      "metadata": {
        "id": "qQNgkCZXkoz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dimension Reduction"
      ],
      "metadata": {
        "id": "sNI3285xZLw3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Dimension%20Reduction.png)"
      ],
      "metadata": {
        "id": "qbzP_cTydxl_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bDujHUO4rhF"
      },
      "source": [
        "Drop additional features:\n",
        "\n",
        "*   stars - not in top features\n",
        "*   review was renamed to 'text' since the field is labeled 'text' in the tokenizing function later\n",
        "*   table service - not in top features, likely correlated with price range\n",
        "*   wifi, accepts reservations - Included originally but it did better without\n",
        "*  accepts credit cards - having this as null was popping to the top so I think it was adding noise"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I tested a handful of combinations (did not have the compute resources to do this super thoroughly)."
      ],
      "metadata": {
        "id": "Z0UBdh5XTEMt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMn86iwcrcPq"
      },
      "outputs": [],
      "source": [
        "columns_to_drop = [\n",
        "                  # 'name',\n",
        "                  # 'state',\n",
        "                  'stars',\n",
        "                  'review', #bc renamed to 'text'\n",
        "                  'attributes.RestaurantsTableService',\n",
        "                  # 'attributes.RestaurantsAttire',\n",
        "                  # 'attributes.RestaurantsDelivery',\n",
        "                  # 'attributes.GoodForKids',\n",
        "                  # 'attributes.GoodForMeal'\n",
        "                  # 'attributes.RestaurantsGoodForGroups',\n",
        "                  # 'attributes.HasTV',\n",
        "                  # 'attributes.BusinessAcceptsBitcoin',\n",
        "                  # 'attributes.RestaurantsTakeOut',\n",
        "                  # 'attributes.Ambience',\n",
        "                  # 'attributes.OutdoorSeating',\n",
        "                  'attributes.BusinessAcceptsCreditCards',\n",
        "                  'attributes.RestaurantsReservations',\n",
        "                  # 'attributes.RestaurantsPriceRange2',\n",
        "                  'attributes.WiFi',\n",
        "                  # 'attributes.NoiseLevel',\n",
        "                  # 'attributes.Alcohol',\n",
        "                  # 'attributes.Caters'\n",
        "                  ]\n",
        "\n",
        "df_train = df_train.drop(columns_to_drop, axis=1)\n",
        "df_test = df_test.drop(columns_to_drop, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.columns"
      ],
      "metadata": {
        "id": "0F3i06KB0qoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Concatenating%20Features.png)"
      ],
      "metadata": {
        "id": "q_VMK2xad0zq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dl_P-fF2SjER"
      },
      "source": [
        "This is the finalization of the data that will go into the model. The restaurant review (called 'text' in the data) starts as the primary source of what would be used in the model to predict restaurant type. All of these other features I have formatted and included are additional to that data and were added to supplement it, so I wanted them to be as succinct and meaningful as possible. The model is essentially predicting from the 'review + other features' to predict the type. The method here to get the single field of data to input into the natural language model is to concatenate the words of the additional features to the review to create one long piece of text. Note using a separator between the features (a period here) is helpful for the model to compartmentalize unrelated text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDFx0x27eZvd"
      },
      "source": [
        "View restaurant review field separately first before concatenating with other features:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbrWUcJ7fFOD"
      },
      "source": [
        "One example of \"text\" value (one restaurant review) before adding features to it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kFaa6mLeY6D"
      },
      "outputs": [],
      "source": [
        "print(df_train['text'].iloc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Concatenate 'text' (review) field with other features:"
      ],
      "metadata": {
        "id": "IYLTXlUsTvCt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNnqaWUYoTZC"
      },
      "outputs": [],
      "source": [
        "# Get all column names except 'label'\n",
        "fields_to_concat = [col for col in df_train.columns if col != 'label']\n",
        "\n",
        "# Concatenate with periods between values\n",
        "df_train[\"concatenated\"] = df_train[fields_to_concat]\\\n",
        "    .fillna(\"\").astype(str)\\\n",
        "    .apply(lambda row: \".\".join(row.values), axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgNJF5ysoWsq"
      },
      "outputs": [],
      "source": [
        "# Ensure all fields are strings and fill NaNs with empty string\n",
        "df_train[fields_to_concat] = df_train[fields_to_concat].fillna('').astype(str)\n",
        "\n",
        "# Concatenate only non-empty fields, separated by '. '\n",
        "df_train[\"text_review_and_features\"] = df_train[fields_to_concat].apply(\n",
        "    lambda row: '. '.join([val for val in row if val.strip() != '']),\n",
        "    axis=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQ4FDNF4oD_P"
      },
      "outputs": [],
      "source": [
        "# Ensure all fields are strings and fill NaNs with empty string\n",
        "df_test[fields_to_concat] = df_test[fields_to_concat].fillna('').astype(str)\n",
        "\n",
        "# Concatenate only non-empty fields, separated by '. '\n",
        "df_test[\"text_review_and_features\"] = df_test[fields_to_concat].apply(\n",
        "    lambda row: '. '.join([val for val in row if val.strip() != '']),\n",
        "    axis=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1161AHcHbHAo"
      },
      "source": [
        "This is the final text field that will be fed into the natural language model. It is a concatenation of features (as text) joined to the restaurant review text, which will be used as one big text field to predict the restaurant type:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLj2jkFafBvF"
      },
      "source": [
        "One example of new \"text\" value (restaurant review + additional features):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clbyyoe9Xspn"
      },
      "outputs": [],
      "source": [
        "print(df_train['text_review_and_features'].iloc[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_test['text_review_and_features'].iloc[0])"
      ],
      "metadata": {
        "id": "P0o6fA4cKMgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h99-Cxve7Bv3"
      },
      "source": [
        "#Average Embedding Models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Average%20Embedding%20Models.png)"
      ],
      "metadata": {
        "id": "SKVJbGwCfc0V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Load%20Libraries.png)"
      ],
      "metadata": {
        "id": "dAnFGLI7fhPP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load libraries for Average Embedding Models:"
      ],
      "metadata": {
        "id": "cByeoBA5VsiD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbz_QX7i7LNg"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import itertools\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import word2vec\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import os\n",
        "import string\n",
        "\n",
        "\n",
        "# NLTK library downloads\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQrAAU1a1J3b"
      },
      "source": [
        "##Data Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Data%20Pre-Processing.png)"
      ],
      "metadata": {
        "id": "qvDzMXBLfkox"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Pre-Processing for Average Word Embeddings:\n",
        "\n",
        "\n",
        "1.   TEXT PRE-PROCESSING | pre-process_df: Clean the data of stopwords, punctuation and single character words\n",
        "2.   TOKENIZATION | tokenize_text_column: Tokenize the Training and Test Data sentences (with nltk tokenizer)\n",
        "3.   BUILD VOCABULARY | build_vocab: Build vocabulary from Tokenized Data\n",
        "4.   inp_data: Create Input Data (indices only) to build sentences of indices of words using Vocabulary and Tokenized Data\n",
        "5.   WORD EMBEDDINGS | get_embeddings: Train Word2Vec Skigram model to get word embedding weights matrix (W) using Vocabulary and Input Data\n",
        "6.   AVERAGE EMBEDDING VECTORS | average_embedding_vectors: Build Avg. Word Embedding Vectors for training and test sets (1 vector for each review)\n",
        "\n"
      ],
      "metadata": {
        "id": "VwvvP23jV7Pj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Functions.png)"
      ],
      "metadata": {
        "id": "sCc6nilrfqqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions for Steps 1-2 and 4-6:"
      ],
      "metadata": {
        "id": "m9wAsJegn4DP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Text%20Pre-Processing.png)"
      ],
      "metadata": {
        "id": "uNETa_Qmftnf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to pre-process raw (English) text:"
      ],
      "metadata": {
        "id": "sdyuJtgNWROu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZvY3aQ27S6m"
      },
      "outputs": [],
      "source": [
        "def preprocess_df(df):\n",
        "    # get English stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    stop_words.add('would')\n",
        "    translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
        "    preprocessed_sentences = []\n",
        "    for i, row in df.iterrows():\n",
        "        sent = row[\"text\"]\n",
        "        sent_nopuncts = sent.translate(translator)\n",
        "        words_list = sent_nopuncts.strip().split()\n",
        "        filtered_words = [word for word in words_list if word not in stop_words and len(word) != 1]\n",
        "        preprocessed_sentences.append(\" \".join(filtered_words))\n",
        "    df[\"text\"] = preprocessed_sentences\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Build%20Vocabulary.png)"
      ],
      "metadata": {
        "id": "TCye1wpjf1t3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to build a vocabulary based on descending word frequencies:"
      ],
      "metadata": {
        "id": "9q7ZSffIV5rr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5MjL9Sk7N1D"
      },
      "outputs": [],
      "source": [
        "def build_vocab(sentences):\n",
        "    word_counts = Counter(itertools.chain(*sentences))\n",
        "    vocabulary_inv = [x[0] for x in word_counts.most_common()]\n",
        "    vocabulary = {x: i for i, x in enumerate(vocabulary_inv)}\n",
        "    return word_counts, vocabulary, vocabulary_inv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Word%20Embeddings.png)"
      ],
      "metadata": {
        "id": "VS7aLTArf5FN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to learn word embeddings through Word2vec module and skigram (builds matrix W):"
      ],
      "metadata": {
        "id": "R3gO8e1HWGkr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zH5WrBfH7SWf"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_embeddings(inp_data, vocabulary_inv, size_features=100, #100 features originally\n",
        "                   mode='skipgram',\n",
        "                   min_word_count=2, #2 originally\n",
        "                   context=5): #5 originally\n",
        "    model_name = \"embedding\"\n",
        "    model_name = os.path.join(model_name)\n",
        "    num_workers = 15  #15 originally\n",
        "    downsampling = 1e-3  # Downsample setting for frequent words\n",
        "    print('Training Word2Vec model...')\n",
        "    sentences = [[vocabulary_inv[w] for w in s] for s in inp_data]\n",
        "    if mode == 'skipgram':\n",
        "        sg = 1\n",
        "        print('Model: skip-gram')\n",
        "    elif mode == 'cbow':\n",
        "        sg = 0\n",
        "        print('Model: CBOW')\n",
        "    embedding_model = word2vec.Word2Vec(sentences, workers=num_workers,\n",
        "                                        sg=sg,\n",
        "                                        vector_size=size_features,\n",
        "                                        min_count=min_word_count,\n",
        "                                        window=context,\n",
        "                                        sample=downsampling,\n",
        "                                        seed=42)\n",
        "    print(\"Saving Word2Vec model {}\".format(model_name))\n",
        "    embedding_weights = np.zeros((len(vocabulary_inv), size_features)) #W\n",
        "    for i in range(len(vocabulary_inv)):\n",
        "        word = vocabulary_inv[i]\n",
        "        if word in embedding_model.wv:\n",
        "            embedding_weights[i] = embedding_model.wv[word]\n",
        "        else:\n",
        "            embedding_weights[i] = np.random.uniform(-0.25, 0.25,\n",
        "                                                     embedding_model.vector_size)\n",
        "    return embedding_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Tokenization.png)"
      ],
      "metadata": {
        "id": "u4wP6IjUf8fC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFePKd3Q7nU9"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def tokenize_text_column(df, column=\"text\"):\n",
        "    \"\"\"\n",
        "    Tokenizes each row in the specified text column using NLTK's word_tokenize.\n",
        "    \"\"\"\n",
        "    return [word_tokenize(str(text)) for text in df[column]]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Average%20Embedding%20Vectors.png)"
      ],
      "metadata": {
        "id": "_1dC8DOYf_kh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wru_FgTxIjPN"
      },
      "outputs": [],
      "source": [
        "def average_embedding_vectors(tokenized_docs, embedding_weights, vocabulary):\n",
        "    vectors = []\n",
        "    embedding_dim = embedding_weights.shape[1]\n",
        "\n",
        "    for doc in tokenized_docs:\n",
        "        vec = np.zeros(embedding_dim)\n",
        "        count = 0\n",
        "        for word in doc:\n",
        "            if word in vocabulary:\n",
        "                vec += embedding_weights[vocabulary[word]]\n",
        "                count += 1\n",
        "        if count > 0:\n",
        "            vec /= count\n",
        "        vectors.append(vec)\n",
        "\n",
        "    return vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Model%201.png)"
      ],
      "metadata": {
        "id": "ojWz59cngD6k"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir7d2aDE6Nk0"
      },
      "source": [
        "##Model 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Run%20Pre-Processing.png)"
      ],
      "metadata": {
        "id": "9xfmjmzkgGyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "1wKbK2reECq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNK-cRK87X9G"
      },
      "outputs": [],
      "source": [
        "# Step 1 Pre-process/tokenize \"text\"\n",
        "df_train_1 = preprocess_df(df_train)\n",
        "df_test_1 = preprocess_df(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPC8KEGnumpS"
      },
      "outputs": [],
      "source": [
        "# Step 2 Tokenize sentences\n",
        "train_1_tokenized = tokenize_text_column(df_train_1, column=\"text\")\n",
        "test_1_tokenized  = tokenize_text_column(df_test_1, column=\"text\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VF_ZZ8vN7aNP"
      },
      "outputs": [],
      "source": [
        "# Step 3 Build Vocabulary of \"text\"\n",
        "word_counts, vocabulary, vocabulary_inv = build_vocab(train_1_tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHhXFZoe7gx8"
      },
      "outputs": [],
      "source": [
        "# use the above mapping to create input data (indices only) to build sentences of indices\n",
        "from datetime import datetime\n",
        "\n",
        "model_1_start = datetime.now()\n",
        "\n",
        "# Step 4 Create Input Data\n",
        "inp_data = [[vocabulary[word] for word in text] for text in train_1_tokenized] #tagged data is in sentences\n",
        "# get embedding vector\n",
        "\n",
        "# Step 5 Word Embeddings\n",
        "embedding_weights = get_embeddings(inp_data, vocabulary_inv)\n",
        "\n",
        "model_1_end = datetime.now()\n",
        "\n",
        "model_1_time = model_1_end - model_1_start\n",
        "print(f\"Model 1 training time: {model_1_time:.2f} seconds\")\n",
        "\n",
        "#Trains Word2Vec model -> not using pre-trained embeddings, training them here"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_weights[0])"
      ],
      "metadata": {
        "id": "mtITyiYOxElF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erlxfiqNInDd"
      },
      "outputs": [],
      "source": [
        "#Step 6 Create Average Word Embedding Vectors\n",
        "train_vec_1 = average_embedding_vectors(train_1_tokenized, embedding_weights, vocabulary)\n",
        "test_vec_1  = average_embedding_vectors(test_1_tokenized, embedding_weights, vocabulary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTERpXtH7cHE"
      },
      "outputs": [],
      "source": [
        "print(train_1_tokenized[0]) #tagged data is in sentences\n",
        "# print(vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgkVdQqY7i_s"
      },
      "outputs": [],
      "source": [
        "print(inp_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-pgg2t27eYc"
      },
      "outputs": [],
      "source": [
        "print(f\"{'word_counts':<15} {'vocabulary':<15} {'vocabulary_inv':<15}\")\n",
        "print(\"-\" * 45)\n",
        "\n",
        "for i, word in enumerate(vocabulary_inv[:10]):  # First 20 entries\n",
        "    count = word_counts[word]\n",
        "    index = vocabulary[word]\n",
        "    print(f\"{str(count):<15} {str({word: index}):<15} {word:<15}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Split%20Data.png)"
      ],
      "metadata": {
        "id": "IjYzhEtmgLrK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split data into 80/10/10 Train, Validation, Test split:"
      ],
      "metadata": {
        "id": "FJq97adMcNfn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAOz9_RJ7yG8"
      },
      "outputs": [],
      "source": [
        "X_1 = train_vec_1\n",
        "y_1 = df_train_1['label']\n",
        "\n",
        "# Train (80%), Temp (20%) split\n",
        "X_train_1, X_temp_1, y_train_1, y_temp_1 = train_test_split(\n",
        "    X_1,y_1,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_1\n",
        ")\n",
        "\n",
        "# Temp â†’ Validation (10%), Test (10%) split\n",
        "X_val_1, X_test_1, y_val_1, y_test_1 = train_test_split(\n",
        "    X_temp_1,\n",
        "    y_temp_1,\n",
        "    test_size=0.5,\n",
        "    random_state=42,\n",
        "    stratify=y_temp_1\n",
        ")\n",
        "\n",
        "# Delete temp vars and print shapes with % of total\n",
        "del X_temp_1, y_temp_1\n",
        "total_samples = len(df_train_1)\n",
        "\n",
        "X_train_1_for_shape = np.array(X_train_1)\n",
        "y_train_1_for_shape = np.array(y_train_1)\n",
        "X_val_1_for_shape = np.array(X_val_1)\n",
        "y_val_1_for_shape = np.array(y_val_1)\n",
        "X_test_1_for_shape = np.array(X_test_1)\n",
        "y_test_1_for_shape = np.array(y_test_1)\n",
        "\n",
        "\n",
        "print(f\"the shape of the training set (input) is: {X_train_1_for_shape.shape} ({len(X_train_1_for_shape)/total_samples:.1%} of total)\")\n",
        "print(f\"the shape of the training set (target) is: {y_train_1_for_shape.shape} ({len(y_train_1_for_shape)/total_samples:.1%} of total)\\n\")\n",
        "\n",
        "print(f\"the shape of the cross validation set (input) is: {X_val_1_for_shape.shape} ({len(X_val_1_for_shape)/total_samples:.1%} of total)\")\n",
        "print(f\"the shape of the cross validation set (target) is: {y_val_1_for_shape.shape} ({len(y_val_1_for_shape)/total_samples:.1%} of total)\\n\")\n",
        "\n",
        "print(f\"the shape of the test set (input) is: {X_test_1_for_shape.shape} ({len(X_test_1_for_shape)/total_samples:.1%} of total)\")\n",
        "print(f\"the shape of the test set (target) is: {y_test_1_for_shape.shape} ({len(y_test_1_for_shape)/total_samples:.1%} of total)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Train%20Model.png)"
      ],
      "metadata": {
        "id": "CP65tPjBgPgD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train average word embedding feature against labels using Logistic Regression:"
      ],
      "metadata": {
        "id": "CzyqniLBcTJM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTB4XaCe6i4I"
      },
      "outputs": [],
      "source": [
        "clf_val_1 = LogisticRegression(max_iter=1000).fit(X_train_1, y_train_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Model%20Accuracy_%20Validation%20Set.png)"
      ],
      "metadata": {
        "id": "TrBLimYKgR3z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate Accuracy of model's Restaurant Predictions:"
      ],
      "metadata": {
        "id": "tKT-NJvdccZ2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsoQkrqRXhUY"
      },
      "outputs": [],
      "source": [
        "preds_val_1 = clf_val_1.predict(X_val_1)\n",
        "\n",
        "val_accuracy_1 = accuracy_score(y_val_1, preds_val_1)\n",
        "print(f\"Validation Accuracy: {val_accuracy_1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Classification%20Report_%20Validation%20Set.png)"
      ],
      "metadata": {
        "id": "OFOPerKGgdNV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate accuracy on individual Restaurant Types:"
      ],
      "metadata": {
        "id": "4AsIhP__choZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Improvements were optimized to the F1 score during modeling*"
      ],
      "metadata": {
        "id": "jNUu5y9lE_iG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08kSERFk71Ly"
      },
      "outputs": [],
      "source": [
        "classification_report_val_1 = classification_report(y_val_1, preds_val_1)\n",
        "print(classification_report_val_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Confusion%20Matrix_%20Validation%20Set.png)"
      ],
      "metadata": {
        "id": "45Umsf3ogzan"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run confusion matrix to see where exactly predictions are going wrong:"
      ],
      "metadata": {
        "id": "asr9h7Cwco2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_val_1, preds_val_1, labels=clf_val_1.classes_)\n",
        "cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # row-wise %\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm_percent, display_labels=clf_val_1.classes_)\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "disp.plot(cmap=plt.cm.Pastel2_r, values_format=\".2f\", ax=ax)\n",
        "# Improve readability\n",
        "for text in ax.texts:\n",
        "    text.set_color(\"black\")\n",
        "\n",
        "plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
        "\n",
        "plt.title(\"Confusion Matrix (Percentages)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i88lFbCjeCoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfRa7_EW6Bw6"
      },
      "source": [
        "##Model 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Model%202.png)"
      ],
      "metadata": {
        "id": "xDK4yEOXg52m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run pre-processing steps on Restaurant Review + Other Features field this time (instead of just the Review only like in Model 1):"
      ],
      "metadata": {
        "id": "9hBprVKqc5aH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "Je9Ptw2gEGcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_start = datetime.now()\n",
        "\n",
        "df_train_2=df_train.copy()\n",
        "df_train_2[\"text\"]=df_train_2[\"text_review_and_features\"]\n",
        "\n",
        "df_test_2=df_test.copy()\n",
        "df_test_2[\"text\"]=df_test_2[\"text_review_and_features\"]\n",
        "\n",
        "# Step 1 Pre-process/tokenize \"text\"\n",
        "df_train_2 = preprocess_df(df_train_2)\n",
        "df_test_2 = preprocess_df(df_test_2)\n",
        "\n",
        "# Step 2 Tokenize sentences\n",
        "train_2_tokenized = tokenize_text_column(df_train_2, column=\"text\")\n",
        "test_2_tokenized  = tokenize_text_column(df_test_2, column=\"text\")\n",
        "\n",
        "# Step 3 Build Vocabulary of \"text\"\n",
        "word_counts, vocabulary, vocabulary_inv = build_vocab(train_2_tokenized)\n",
        "\n",
        "# Step 4 Create Input Data\n",
        "inp_data = [[vocabulary[word] for word in text] for text in train_2_tokenized] #tagged data is in sentences\n",
        "\n",
        "# Step 5 Word Embeddings\n",
        "embedding_weights = get_embeddings(inp_data, vocabulary_inv)\n",
        "\n",
        "#Step 6 Create Average Word Embedding Vectors\n",
        "train_vec_2 = average_embedding_vectors(train_2_tokenized, embedding_weights, vocabulary)\n",
        "test_vec_2  = average_embedding_vectors(test_2_tokenized, embedding_weights, vocabulary)\n",
        "\n",
        "model_2_end = datetime.now()\n",
        "\n",
        "model_2_time = model_2_end - model_2_start\n",
        "print(f\"Model 1 training time: {model_2_time:.2f} seconds\")"
      ],
      "metadata": {
        "id": "tWsobCKK_fRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_2_tokenized[0]) #tagged data is in sentences"
      ],
      "metadata": {
        "id": "ayGd0Qc3cwTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Split%20Data.png)"
      ],
      "metadata": {
        "id": "xz72a47Cg85t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split data into 80/10/10 Train, Validation, Test split:"
      ],
      "metadata": {
        "id": "0vvyJ4ARdIz8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFb96k1Y4CDD"
      },
      "outputs": [],
      "source": [
        "X_2=train_vec_2\n",
        "y_2=df_train_2['label']\n",
        "\n",
        "# Train (80%), Temp (20%) split\n",
        "X_train_2, X_temp_2, y_train_2, y_temp_2 = train_test_split(\n",
        "    X_2,y_2,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_2\n",
        ")\n",
        "\n",
        "# Temp â†’ Validation (10%), Test (10%) split\n",
        "X_val_2, X_test_2, y_val_2, y_test_2 = train_test_split(\n",
        "    X_temp_2,\n",
        "    y_temp_2,\n",
        "    test_size=0.5,\n",
        "    random_state=42,\n",
        "    stratify=y_temp_2\n",
        ")\n",
        "\n",
        "# Delete temp vars and print shapes with % of total\n",
        "del X_temp_2, y_temp_2\n",
        "total_samples_2 = len(df_train_2)\n",
        "\n",
        "X_train_2_for_shape = np.array(X_train_2)\n",
        "y_train_2_for_shape = np.array(y_train_2)\n",
        "X_val_2_for_shape = np.array(X_val_2)\n",
        "y_val_2_for_shape = np.array(y_val_2)\n",
        "X_test_2_for_shape = np.array(X_test_2)\n",
        "y_test_2_for_shape = np.array(y_test_2)\n",
        "\n",
        "\n",
        "print(f\"the shape of the training set (input) is: {X_train_2_for_shape.shape} ({len(X_train_2_for_shape)/total_samples_2:.1%} of total)\")\n",
        "print(f\"the shape of the training set (target) is: {y_train_2_for_shape.shape} ({len(y_train_2_for_shape)/total_samples_2:.1%} of total)\\n\")\n",
        "\n",
        "print(f\"the shape of the cross validation set (input) is: {X_val_2_for_shape.shape} ({len(X_val_2_for_shape)/total_samples_2:.1%} of total)\")\n",
        "print(f\"the shape of the cross validation set (target) is: {y_val_2_for_shape.shape} ({len(y_val_2_for_shape)/total_samples_2:.1%} of total)\\n\")\n",
        "\n",
        "print(f\"the shape of the test set (input) is: {X_test_2_for_shape.shape} ({len(X_test_2_for_shape)/total_samples_2:.1%} of total)\")\n",
        "print(f\"the shape of the test set (target) is: {y_test_2_for_shape.shape} ({len(y_test_2_for_shape)/total_samples_2:.1%} of total)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Train%20Model.png)"
      ],
      "metadata": {
        "id": "DunAivMNg_sS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model on Logistic Regression:"
      ],
      "metadata": {
        "id": "cnJr9tXOdN5r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6_UidwipfhN"
      },
      "outputs": [],
      "source": [
        "clf_val_2 = LogisticRegression(max_iter=1000).fit(X_train_2, y_train_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Model%20Accuracy_%20Validation%20Set.png)"
      ],
      "metadata": {
        "id": "Qc6yP7DuhCZa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate Accuracy:"
      ],
      "metadata": {
        "id": "AjVLB8ntdRYG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yU868cIRwFZ9"
      },
      "outputs": [],
      "source": [
        "preds_val_2 = clf_val_2.predict(X_val_2)\n",
        "\n",
        "val_accuracy_2 = accuracy_score(y_val_2, preds_val_2)\n",
        "print(f\"Validation Accuracy: {val_accuracy_2:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate Accuracy of individual Restaurant Type predictions:"
      ],
      "metadata": {
        "id": "5P7aIcl5dTSM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfV2OZojwNIY"
      },
      "outputs": [],
      "source": [
        "classification_report_val_2 = classification_report(y_val_2, preds_val_2)\n",
        "print(classification_report_val_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Confusion%20Matrix_%20Test%20Set.png)"
      ],
      "metadata": {
        "id": "XJGnOWvvhHAT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run confusion matrix to see where predictions are going wrong:\n"
      ],
      "metadata": {
        "id": "KnFnUvdRdYbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_val_2, preds_val_2, labels=clf_val_2.classes_)\n",
        "cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # row-wise %\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm_percent, display_labels=clf_val_2.classes_)\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "disp.plot(cmap=plt.cm.Pastel2_r, values_format=\".2f\", ax=ax)\n",
        "\n",
        "# Improve readability\n",
        "for text in ax.texts:\n",
        "    text.set_color(\"black\")\n",
        "\n",
        "plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
        "\n",
        "plt.title(\"Confusion Matrix (Percentages)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rV3EU90iecXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmyCqwti0l9y"
      },
      "source": [
        "#BERT Transformer Models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/BERT%20Transformer%20Models.png)"
      ],
      "metadata": {
        "id": "K3h1tS30h4p2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Load%20Libraries.png)"
      ],
      "metadata": {
        "id": "Cve7SBZXhO5E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfE7PBxAcIGJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from transformers import (\n",
        "    BertTokenizerFast,\n",
        "    BertForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "import random\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Set%20Seed.png)"
      ],
      "metadata": {
        "id": "udVfjTUTh_4-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egvTSueHcU7R"
      },
      "source": [
        "Set seed for reproducibility, but NOTE IT IS NOT 100% reproducible, as there is still some level of randomness in Hugging Face Transformer models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLPO0ZwecaaU"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # when using GPU\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Encode%20Labels.png)"
      ],
      "metadata": {
        "id": "BQAzuqLFiCvk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cwCCOpZcsf4"
      },
      "source": [
        "Encode labels as numbers (e.g., \"Italian\" -> class \"1\"):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5kxhLrsch9s"
      },
      "outputs": [],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df_train[\"label\"].values)\n",
        "num_classes = len(label_encoder.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10CD-oMj-OEN"
      },
      "outputs": [],
      "source": [
        "print(df_train[\"label\"].values)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRmbbe9-NRXH"
      },
      "source": [
        "##Model 3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Model%203.png)"
      ],
      "metadata": {
        "id": "VAyUzp4YiGZi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Split%20Data.png)"
      ],
      "metadata": {
        "id": "XfdTzDQqiJX-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoM1Vr-Icv9P"
      },
      "source": [
        "Split labeled training data into training (80%), validation (10%) and test (10%) sets. This is a common split for NLP and a dataset of this size (13k rows). It also performed better than 70%/15%/15%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Nl23Qihcvpa"
      },
      "outputs": [],
      "source": [
        "X_3=df_train[\"text\"].values\n",
        "y_3=y\n",
        "\n",
        "# Train (80%), Temp (20%) split\n",
        "X_train_3, X_temp_3, y_train_3, y_temp_3 = train_test_split(\n",
        "    X_3,\n",
        "    y_3,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_3\n",
        ")\n",
        "\n",
        "# Temp â†’ Validation (10%), Test (10%) split\n",
        "X_val_3, X_test_3, y_val_3, y_test_3 = train_test_split(\n",
        "    X_temp_3,\n",
        "    y_temp_3,\n",
        "    test_size=0.5,\n",
        "    random_state=42,\n",
        "    stratify=y_temp_3\n",
        ")\n",
        "\n",
        "# Delete temp vars and print shapes with % of total\n",
        "del X_temp_3, y_temp_3\n",
        "total_samples_3 = len(df_train)\n",
        "\n",
        "print(f\"the shape of the training set (input) is: {X_train_3.shape} ({len(X_train_3)/total_samples_3:.1%} of total)\")\n",
        "print(f\"the shape of the training set (target) is: {y_train_3.shape} ({len(y_train_3)/total_samples_3:.1%} of total)\\n\")\n",
        "\n",
        "print(f\"the shape of the cross validation set (input) is: {X_val_3.shape} ({len(X_val_3)/total_samples_3:.1%} of total)\")\n",
        "print(f\"the shape of the cross validation set (target) is: {y_val_3.shape} ({len(y_val_3)/total_samples_3:.1%} of total)\\n\")\n",
        "\n",
        "print(f\"the shape of the test set (input) is: {X_test_3.shape} ({len(X_test_3)/total_samples_3:.1%} of total)\")\n",
        "print(f\"the shape of the test set (target) is: {y_test_3.shape} ({len(y_test_3)/total_samples_3:.1%} of total)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Tokenize%20Data.png)"
      ],
      "metadata": {
        "id": "941aOg-JiNqQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ah4v0Wwvw2w_"
      },
      "source": [
        "Tokenize the text using Bert Tokenizer. Caps each observation at 512 tokens:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Uqt7KCZpZ18"
      },
      "source": [
        "*(I tested out different levels but this is the max the model can use and performed the best when it captured as much of the review as possible)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpqyRbx-cxdv"
      },
      "outputs": [],
      "source": [
        "bert_tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def tokenize_texts_with_bert(texts, max_length=512):\n",
        "  #truncates at 512 tokens per row\n",
        "    return bert_tokenizer(\n",
        "        list(texts),\n",
        "        max_length=max_length,\n",
        "        padding='max_length',\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "train_encodings_3 = tokenize_texts_with_bert(X_train_3)\n",
        "val_encodings_3 = tokenize_texts_with_bert(X_val_3)\n",
        "test_encodings_3 = tokenize_texts_with_bert(X_test_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Create%20Dataset%20Objects.png)"
      ],
      "metadata": {
        "id": "pboxdAJ2iRer"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQnZJdRfx6Ut"
      },
      "source": [
        "Creates Hugging Face dataset objects from a Python dictionary of an id, tokenized texts and their labels, to use in training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDJgyv3-ydaE"
      },
      "outputs": [],
      "source": [
        "train_dataset_3 = Dataset.from_dict({\n",
        "    'input_ids': train_encodings_3['input_ids'],\n",
        "    'attention_mask': train_encodings_3['attention_mask'],\n",
        "    'labels': list(y_train_3)\n",
        "})\n",
        "\n",
        "val_dataset_3 = Dataset.from_dict({\n",
        "    'input_ids': val_encodings_3['input_ids'],\n",
        "    'attention_mask': val_encodings_3['attention_mask'],\n",
        "    'labels': list(y_val_3)\n",
        "})\n",
        "\n",
        "test_dataset_3 = Dataset.from_dict({\n",
        "    'input_ids': test_encodings_3['input_ids'],\n",
        "    'attention_mask': test_encodings_3['attention_mask'],\n",
        "    'labels': list(y_test_3)\n",
        "})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Train%20Model.png)"
      ],
      "metadata": {
        "id": "w6FQ791UiX1o"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4vWPe1Lyg4L"
      },
      "source": [
        "Call BERT model for classification:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftTiyxl-ynzH"
      },
      "outputs": [],
      "source": [
        "model_3 = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    num_labels=num_classes,\n",
        ")\n",
        "#default dropout is 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTLClYUwyneV"
      },
      "source": [
        "Train the BERT model with the following arguments:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQGcaJg4dNfP"
      },
      "outputs": [],
      "source": [
        "training_args_bert = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=4, #3-5 recommended, lower prevents overfitting\n",
        "    learning_rate=2e-5, #want lower if data is noisy/smaller\n",
        "    per_device_train_batch_size=16, #lower (8,16) uses less memory\n",
        "    per_device_eval_batch_size=16,\n",
        "    warmup_steps=100,\n",
        "    #gradually increases learning rate at start of training to prevent destabilizing of gradient descent\n",
        "    weight_decay=0.009, #regularizes to prevent overfitting\n",
        "    logging_dir='./logs',\n",
        "    eval_strategy='epoch', #epochs vs. early stopping\n",
        "    save_strategy='epoch',\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"none\",  # disables W&B logging\n",
        "    run_name='bert-review-classifier',\n",
        "    seed=42\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I59D4JZVywh_"
      },
      "source": [
        "Build function to calculate accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLuCDfRVdUCe"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(labels, predictions)\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9Vanstmy2K8"
      },
      "source": [
        "Train the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qGet4Fdddqn"
      },
      "outputs": [],
      "source": [
        "model_3_start = datetime.now()\n",
        "\n",
        "bert_trainer_3 = Trainer(\n",
        "    model=model_3,\n",
        "    args=training_args_bert,\n",
        "    train_dataset=train_dataset_3,\n",
        "    eval_dataset=val_dataset_3,  # val set used during training\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "bert_trainer_3.train()\n",
        "\n",
        "model_3_end = datetime.now()\n",
        "\n",
        "model_3_time = model_3_end - model_3_start\n",
        "print(f\"Model 1 training time: {model_3_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Model%20Accuracy_%20Validation%20Set.png)"
      ],
      "metadata": {
        "id": "nLqKQUX4icCp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK1TluYxy-tk"
      },
      "source": [
        "Evaluate the accuracy of the predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwjnnZemdl3n"
      },
      "outputs": [],
      "source": [
        "val_results_3 = bert_trainer_3.evaluate(val_dataset_3)\n",
        "print(f\"\\n Validation Accuracy: {val_results_3['eval_accuracy']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Classification%20Report_%20Validation%20Set.png)"
      ],
      "metadata": {
        "id": "6jsilKMTihoA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAhp-IQRggJ0"
      },
      "source": [
        "View accuracy by class (restaurant type) and accuracy type (precision vs. recall vs. F1):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvfTrhU6dMxJ"
      },
      "source": [
        "Improvements were optimized to the F1 score during modeling:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RN7-v5ROd-uw"
      },
      "outputs": [],
      "source": [
        "val_predictions_3 = bert_trainer_3.predict(val_dataset_3)\n",
        "y_val_pred_3 = np.argmax(val_predictions_3.predictions, axis=1)\n",
        "y_val_true_3 = val_predictions_3.label_ids\n",
        "\n",
        "val_report_3 = classification_report(y_val_true_3, y_val_pred_3, target_names=label_encoder.classes_)\n",
        "print(\"\\n Validation Classification Report:\\n\", val_report_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Confusion%20Matrix_%20Validation%20Set.png)"
      ],
      "metadata": {
        "id": "zahXzHanipbt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run confusion matrix to see where exactly predictions are going wrong:"
      ],
      "metadata": {
        "id": "8Z5Yd9ScFO-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This gives the original labels in the correct encoded order\n",
        "label_names = label_encoder.classes_\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Compute confusion matrix and percentages\n",
        "cm = confusion_matrix(y_val_true_3, y_val_pred_3, labels=range(len(label_names)))\n",
        "cm_percent = cm.astype(float) / cm.sum(axis=1, keepdims=True)\n",
        "\n",
        "# Plot\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm_percent, display_labels=label_names)\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "disp.plot(cmap=plt.cm.Pastel2_r, values_format=\".2f\", ax=ax)\n",
        "\n",
        "# Improve readability\n",
        "for text in ax.texts:\n",
        "    text.set_color(\"black\")\n",
        "\n",
        "plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
        "plt.title(\"Confusion Matrix (Percentages)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "er8QOgDV0hwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JL5WNzgt2sP8"
      },
      "source": [
        "##Model 4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Model%204.png)"
      ],
      "metadata": {
        "id": "hQILc99eiySr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Split%20Data.png)"
      ],
      "metadata": {
        "id": "sFrdxsJci06i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform same steps as Model 3:"
      ],
      "metadata": {
        "id": "vMJc8moYFUm8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split data into 80/10/10 Train, Validation, Test split:"
      ],
      "metadata": {
        "id": "anJJDgMSFbEq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnF7rhrcBWHa"
      },
      "outputs": [],
      "source": [
        "X_4=df_train[\"text_review_and_features\"].values\n",
        "y_4=y\n",
        "\n",
        "# Train (80%), Temp (20%) split\n",
        "X_train_4, X_temp_4, y_train_4, y_temp_4 = train_test_split(\n",
        "    X_4,\n",
        "    y_4,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_4\n",
        ")\n",
        "\n",
        "# Temp â†’ Validation (10%), Test (10%) split\n",
        "X_val_4, X_test_4, y_val_4, y_test_4 = train_test_split(\n",
        "    X_temp_4,\n",
        "    y_temp_4,\n",
        "    test_size=0.5,\n",
        "    random_state=42,\n",
        "    stratify=y_temp_4\n",
        ")\n",
        "\n",
        "# Delete temp vars and print shapes with % of total\n",
        "del X_temp_4, y_temp_4\n",
        "total_samples_4 = len(df_train)\n",
        "\n",
        "print(f\"the shape of the training set (input) is: {X_train_4.shape} ({len(X_train_4)/total_samples_4:.1%} of total)\")\n",
        "print(f\"the shape of the training set (target) is: {y_train_4.shape} ({len(y_train_4)/total_samples_4:.1%} of total)\\n\")\n",
        "\n",
        "print(f\"the shape of the cross validation set (input) is: {X_val_4.shape} ({len(X_val_4)/total_samples_4:.1%} of total)\")\n",
        "print(f\"the shape of the cross validation set (target) is: {y_val_4.shape} ({len(y_val_4)/total_samples_4:.1%} of total)\\n\")\n",
        "\n",
        "print(f\"the shape of the test set (input) is: {X_test_4.shape} ({len(X_test_4)/total_samples_4:.1%} of total)\")\n",
        "print(f\"the shape of the test set (target) is: {y_test_4.shape} ({len(y_test_4)/total_samples_4:.1%} of total)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jni492VDBxUW"
      },
      "outputs": [],
      "source": [
        "train_encodings_4 = tokenize_texts_with_bert(X_train_4)\n",
        "val_encodings_4 = tokenize_texts_with_bert(X_val_4)\n",
        "test_encodings_4 = tokenize_texts_with_bert(X_test_4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Train%20Model.png)"
      ],
      "metadata": {
        "id": "Xf3aZKGJi3-Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Hugging Face Datasets for Train, Val, Test:"
      ],
      "metadata": {
        "id": "rxxDFkRcFhRI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnLV9ZrXCSJO"
      },
      "outputs": [],
      "source": [
        "train_dataset_4 = Dataset.from_dict({\n",
        "    'input_ids': train_encodings_4['input_ids'],\n",
        "    'attention_mask': train_encodings_4['attention_mask'],\n",
        "    'labels': list(y_train_4)\n",
        "})\n",
        "\n",
        "val_dataset_4 = Dataset.from_dict({\n",
        "    'input_ids': val_encodings_4['input_ids'],\n",
        "    'attention_mask': val_encodings_4['attention_mask'],\n",
        "    'labels': list(y_val_4)\n",
        "})\n",
        "\n",
        "test_dataset_4 = Dataset.from_dict({\n",
        "    'input_ids': test_encodings_4['input_ids'],\n",
        "    'attention_mask': test_encodings_4['attention_mask'],\n",
        "    'labels': list(y_test_4)\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call pre-trained BERT model:"
      ],
      "metadata": {
        "id": "x6krR8O3Fm1L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCkhEsv2CdoP"
      },
      "outputs": [],
      "source": [
        "model_4 = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    num_labels=num_classes,\n",
        ")\n",
        "#default dropout is 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model:"
      ],
      "metadata": {
        "id": "UMB6TGE4FqUH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0LHMzmNCmQR"
      },
      "outputs": [],
      "source": [
        "model_4_start = datetime.now()\n",
        "\n",
        "bert_trainer_4 = Trainer(\n",
        "    model=model_4,\n",
        "    args=training_args_bert, #used same training args as model 3\n",
        "    train_dataset=train_dataset_4,\n",
        "    eval_dataset=val_dataset_4,  # val set used during training\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "bert_trainer_4.train()\n",
        "\n",
        "model_4_end = datetime.now()\n",
        "\n",
        "model_4_time = model_4_end - model_4_start\n",
        "print(f\"Model 1 training time: {model_4_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Model%20Accuracy_%20Validation%20Set.png)"
      ],
      "metadata": {
        "id": "wBkeS1Hti7gJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate accuracy:"
      ],
      "metadata": {
        "id": "2a8Od3PhFs1K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vui-JZRnCrMu"
      },
      "outputs": [],
      "source": [
        "val_results_4 = bert_trainer_4.evaluate(val_dataset_4)\n",
        "print(f\"\\n Validation Accuracy: {val_results_4['eval_accuracy']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run classification report to view accuracy by Restaurant Type (class):"
      ],
      "metadata": {
        "id": "-B5gl3ZhFu4a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juz4GueLCx05"
      },
      "outputs": [],
      "source": [
        "val_predictions_4 = bert_trainer_4.predict(val_dataset_4)\n",
        "y_val_pred_4 = np.argmax(val_predictions_4.predictions, axis=1)\n",
        "y_val_true_4 = val_predictions_4.label_ids\n",
        "\n",
        "val_report_4 = classification_report(y_val_true_4, y_val_pred_4, target_names=label_encoder.classes_)\n",
        "print(\"\\n Validation Classification Report:\\n\", val_report_4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Confusion%20Matrix_%20Validation%20Set.png)"
      ],
      "metadata": {
        "id": "Nsh2lOp4jA6G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run Confusion Matrix to see where predictions are going wrong:"
      ],
      "metadata": {
        "id": "x41YUJZeF2dg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This gives the original labels in the correct encoded order\n",
        "label_names = label_encoder.classes_\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Compute confusion matrix and percentages\n",
        "cm = confusion_matrix(y_val_true_4, y_val_pred_4, labels=range(len(label_names)))\n",
        "cm_percent = cm.astype(float) / cm.sum(axis=1, keepdims=True)\n",
        "\n",
        "# Plot\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm_percent, display_labels=label_names)\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "disp.plot(cmap=plt.cm.Pastel2_r, values_format=\".2f\", ax=ax)\n",
        "\n",
        "# Improve readability\n",
        "for text in ax.texts:\n",
        "    text.set_color(\"black\")\n",
        "\n",
        "plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
        "plt.title(\"Confusion Matrix (Percentages)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cPInLY5Q0Qkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VUOlEPd0uiM"
      },
      "source": [
        "#RoBERTa Transformer Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/RoBERTa%20Transformer%20Model.png)"
      ],
      "metadata": {
        "id": "5i9Cw0B0jHiO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qy-UWADF18FP"
      },
      "source": [
        "##Model 5"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Model%205.png)"
      ],
      "metadata": {
        "id": "aq4Hq84hjLjJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use a different transformer model (Roberta) and run it on the Review + Other Features data as Model 5:"
      ],
      "metadata": {
        "id": "D70Bb7k_GLRe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Differences between RoBERTa and BERT:\n",
        "\n",
        "\n",
        "*   RoBERTa is trained on more data with longer training and bigger batches\n",
        "*   It removes Next Sentence Prediction, focusing only on masked language modeling\n",
        "*  Uses dynamic masking (changing masked tokens during training) instead of static masking\n",
        "*  Has improved hyperparameters and training setup for better performance\n",
        "* Overall, RoBERTa achieves higher accuracy and is more robust than BERT"
      ],
      "metadata": {
        "id": "cTCtzMX9vujN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Load%20Libraries.png)"
      ],
      "metadata": {
        "id": "3zGh-5N2jN7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load libraries for RoBERTa model:"
      ],
      "metadata": {
        "id": "uEOOnRq_F9LH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkO3u53Zb2pP"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    RobertaTokenizerFast,\n",
        "    RobertaForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Split%20Data.png)"
      ],
      "metadata": {
        "id": "aQbUZgW8jPUh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split data into 80/10/10 Train, Validation, Test:"
      ],
      "metadata": {
        "id": "W3azCX44GF45"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAeEjuSvZLId"
      },
      "outputs": [],
      "source": [
        "X_5=df_train[\"text_review_and_features\"].values\n",
        "y_5=y\n",
        "\n",
        "# Train (80%), Temp (20%) split\n",
        "X_train_5, X_temp_5, y_train_5, y_temp_5 = train_test_split(\n",
        "    X_5,\n",
        "    y_5,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_5\n",
        ")\n",
        "\n",
        "# Temp â†’ Validation (10%), Test (10%) split\n",
        "X_val_5, X_test_5, y_val_5, y_test_5 = train_test_split(\n",
        "    X_temp_5,\n",
        "    y_temp_5,\n",
        "    test_size=0.5,\n",
        "    random_state=42,\n",
        "    stratify=y_temp_5\n",
        ")\n",
        "\n",
        "# Delete temp vars and print shapes with % of total\n",
        "del X_temp_5, y_temp_5\n",
        "total_samples_5 = len(df_train)\n",
        "\n",
        "print(f\"the shape of the training set (input) is: {X_train_5.shape} ({len(X_train_5)/total_samples_5:.1%} of total)\")\n",
        "print(f\"the shape of the training set (target) is: {y_train_5.shape} ({len(y_train_5)/total_samples_5:.1%} of total)\\n\")\n",
        "\n",
        "print(f\"the shape of the cross validation set (input) is: {X_val_5.shape} ({len(X_val_5)/total_samples_5:.1%} of total)\")\n",
        "print(f\"the shape of the cross validation set (target) is: {y_val_5.shape} ({len(y_val_5)/total_samples_5:.1%} of total)\\n\")\n",
        "\n",
        "print(f\"the shape of the test set (input) is: {X_test_5.shape} ({len(X_test_5)/total_samples_5:.1%} of total)\")\n",
        "print(f\"the shape of the test set (target) is: {y_test_5.shape} ({len(y_test_5)/total_samples_5:.1%} of total)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize data with pre-trained Roberta model:"
      ],
      "metadata": {
        "id": "hHctEMG6GYX2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFjezB1IdAxw"
      },
      "outputs": [],
      "source": [
        "roberta_tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
        "\n",
        "def tokenize_texts_with_roberta(texts, max_length=512):\n",
        "  #truncates at 512 tokens per row\n",
        "    return roberta_tokenizer(\n",
        "        list(texts),\n",
        "        max_length=max_length,\n",
        "        padding='max_length',\n",
        "        truncation=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIJa8uPPZooW"
      },
      "outputs": [],
      "source": [
        "train_encodings_5 = tokenize_texts_with_roberta(X_train_5)\n",
        "val_encodings_5 = tokenize_texts_with_roberta(X_val_5)\n",
        "test_encodings_5 = tokenize_texts_with_roberta(X_test_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Train%20Model.png)"
      ],
      "metadata": {
        "id": "PD5SjD1IjS5G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Hugging Face datasets for Train, Val, Test:"
      ],
      "metadata": {
        "id": "EyKeicBwGbWl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKGhUZlLZvev"
      },
      "outputs": [],
      "source": [
        "train_dataset_5 = Dataset.from_dict({\n",
        "    'input_ids': train_encodings_5['input_ids'],\n",
        "    'attention_mask': train_encodings_5['attention_mask'],\n",
        "    'labels': list(y_train_5)\n",
        "})\n",
        "\n",
        "val_dataset_5 = Dataset.from_dict({\n",
        "    'input_ids': val_encodings_5['input_ids'],\n",
        "    'attention_mask': val_encodings_5['attention_mask'],\n",
        "    'labels': list(y_val_5)\n",
        "})\n",
        "\n",
        "test_dataset_5 = Dataset.from_dict({\n",
        "    'input_ids': test_encodings_5['input_ids'],\n",
        "    'attention_mask': test_encodings_5['attention_mask'],\n",
        "    'labels': list(y_test_5)\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call RoBERTA model, this one includes dropout regularization of 0.1\n",
        "Dropout randomly sets a percentage of the layerâ€™s outputs to 0 in training\n",
        "to force the model not to rely too much on any one neuron"
      ],
      "metadata": {
        "id": "DyVzr7BHG6k6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlbN2wIndYFO"
      },
      "outputs": [],
      "source": [
        "# Load model with dropout regularization (default dropout for RoBERTa is 0.1)\n",
        "model_5 = RobertaForSequenceClassification.from_pretrained(\n",
        "    'roberta-base',\n",
        "    num_labels=num_classes,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set training arguments:"
      ],
      "metadata": {
        "id": "GDnuM3zgHOiB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaNAN6-qbr8Y"
      },
      "outputs": [],
      "source": [
        "#Training arguments\n",
        "training_args_roberta = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=4, #lower prevents overfitting\n",
        "    learning_rate=2e-5, #want lower if data is noisy/smaller\n",
        "    per_device_train_batch_size=16, #lower (8,16) uses less memory\n",
        "    per_device_eval_batch_size=16,\n",
        "    warmup_steps=100,\n",
        "    #gradually increases learning rate at start of training to prevent destabilizing of gradient descent\n",
        "    weight_decay=0.009, #regularizes to prevent overfitting\n",
        "    logging_dir='./logs',\n",
        "    eval_strategy='epoch', #epochs vs. early stopping\n",
        "    save_strategy='epoch',\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"none\",  # disables W&B logging\n",
        "    run_name='roberta-review-classifier'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model:"
      ],
      "metadata": {
        "id": "UhAsKuqzHfRU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYAaAIdGd9Kp"
      },
      "outputs": [],
      "source": [
        "model_5_start = datetime.now()\n",
        "\n",
        "roberta_trainer_5 = Trainer(\n",
        "    model=model_5,\n",
        "    args=training_args_roberta,\n",
        "    train_dataset=train_dataset_5,\n",
        "    eval_dataset=val_dataset_5,  # val set used during training\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "roberta_trainer_5.train()\n",
        "\n",
        "model_5_end = datetime.now()\n",
        "\n",
        "model_5_time = model_5_end - model_5_start\n",
        "print(f\"Model 1 training time: {model_5_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Model%20Accuracy_%20Validation%20Set.png)"
      ],
      "metadata": {
        "id": "nFIm9blPjWNB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate accuracy of predictions:"
      ],
      "metadata": {
        "id": "XkCnJk0fHkNR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JABrHopHebEd"
      },
      "outputs": [],
      "source": [
        "val_results_5 = roberta_trainer_5.evaluate(val_dataset_5)\n",
        "print(f\"\\n Validation Accuracy: {val_results_5['eval_accuracy']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run classification report to show accuracy on Restaurant Type (class) level:"
      ],
      "metadata": {
        "id": "IRV-k4tGHnHH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEIbNKRlehnu"
      },
      "outputs": [],
      "source": [
        "val_predictions_5 = roberta_trainer_5.predict(val_dataset_5)\n",
        "y_val_pred_5 = np.argmax(val_predictions_5.predictions, axis=1)\n",
        "y_val_true_5 = val_predictions_5.label_ids\n",
        "\n",
        "val_report_5 = classification_report(y_val_true_5, y_val_pred_5, target_names=label_encoder.classes_)\n",
        "print(\"\\n Validation Classification Report:\\n\", val_report_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run confusion matrix to see where predictions are going wrong:"
      ],
      "metadata": {
        "id": "wwP6R5DLHsXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # This gives the original labels in the correct encoded order\n",
        "# label_names = label_encoder.classes_\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Compute confusion matrix and percentages\n",
        "cm = confusion_matrix(y_val_true_5, y_val_pred_5, labels=range(len(label_names)))\n",
        "cm_percent = cm.astype(float) / cm.sum(axis=1, keepdims=True)\n",
        "\n",
        "# Plot\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm_percent, display_labels=label_names)\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "disp.plot(cmap=plt.cm.Pastel2_r, values_format=\".2f\", ax=ax)\n",
        "\n",
        "# Improve readability\n",
        "for text in ax.texts:\n",
        "    text.set_color(\"black\")\n",
        "\n",
        "plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
        "plt.title(\"Confusion Matrix (Percentages)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VQdoTKUq0zeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSljNK9KRc7i"
      },
      "source": [
        "#Model Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Model%20Comparison.png)"
      ],
      "metadata": {
        "id": "TLoNMiayjbZ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Test%20Set%20Accuracies%20All%20Models.png)"
      ],
      "metadata": {
        "id": "mS8ASJEDlVhq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp-CAELXfwiC"
      },
      "source": [
        "Model 1 Test Accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nes_48tYfzC-"
      },
      "outputs": [],
      "source": [
        "clf_test_1 = LogisticRegression(max_iter=1000).fit(train_vec_1, df_train_1[\"label\"])\n",
        "\n",
        "preds_test_1 = clf_test_1.predict(X_test_1)\n",
        "\n",
        "test_accuracy_1 = accuracy_score(y_test_1, preds_test_1)\n",
        "print(f\"Model 1 Test Accuracy: {test_accuracy_1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YB__gFx3f-AH"
      },
      "outputs": [],
      "source": [
        "classification_report_test_1=classification_report(y_test_1, preds_test_1, zero_division=0)\n",
        "print(classification_report_test_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 2 Test Accuracy:"
      ],
      "metadata": {
        "id": "SLxtwBN6IJaE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AICGoDMigwcK"
      },
      "outputs": [],
      "source": [
        "clf_test_2 = LogisticRegression(max_iter=1000).fit(train_vec_2, df_train_2[\"label\"])\n",
        "\n",
        "preds_test_2 = clf_test_2.predict(X_test_2)\n",
        "\n",
        "test_accuracy_2 = accuracy_score(y_test_2, preds_test_2)\n",
        "print(f\"Model 2 Test Accuracy: {test_accuracy_2:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3snAr1XkgtEz"
      },
      "outputs": [],
      "source": [
        "classification_report_test_2 = classification_report(y_test_2, preds_test_2)\n",
        "print(classification_report_test_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 3 Test Accuracy:"
      ],
      "metadata": {
        "id": "EfqFBb7UILow"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLJyZcXidzH0"
      },
      "outputs": [],
      "source": [
        "test_predictions_3 = bert_trainer_3.predict(test_dataset_3)\n",
        "y_test_pred_3 = np.argmax(test_predictions_3.predictions, axis=1)\n",
        "y_test_true_3 = test_predictions_3.label_ids\n",
        "\n",
        "test_accuracy_3 = bert_trainer_3.evaluate(test_dataset_3)\n",
        "print(f\"\\n Model 3 Test Accuracy: {test_accuracy_3['eval_accuracy']:.4f}\")\n",
        "test_accuracy_3 = test_accuracy_3['eval_accuracy']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QS5qUJBeA99"
      },
      "outputs": [],
      "source": [
        "classification_report_test_3 = classification_report(y_test_true_3, y_test_pred_3, target_names=label_encoder.classes_)\n",
        "print(\"\\n Model 3 Test Classification Report:\\n\", classification_report_test_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 4 Test Accuracy:"
      ],
      "metadata": {
        "id": "Hk81SzFVIO0f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCelVbtKMxDt"
      },
      "outputs": [],
      "source": [
        "test_predictions_4 = bert_trainer_4.predict(test_dataset_4)\n",
        "y_test_pred_4 = np.argmax(test_predictions_4.predictions, axis=1)\n",
        "y_test_true_4 = test_predictions_4.label_ids\n",
        "\n",
        "test_accuracy_4 = bert_trainer_4.evaluate(test_dataset_4)\n",
        "print(f\"\\n Model 4 Test Accuracy: {test_accuracy_4['eval_accuracy']:.4f}\")\n",
        "test_accuracy_4 = test_accuracy_4['eval_accuracy']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7l7943gFMyip"
      },
      "outputs": [],
      "source": [
        "classification_report_test_4 = classification_report(y_test_true_4, y_test_pred_4, target_names=label_encoder.classes_)\n",
        "print(\"\\n Model 4 Test Classification Report:\\n\", classification_report_test_4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 5 Test Accuracy:"
      ],
      "metadata": {
        "id": "5_zwmX6UIRDA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sXmj8LIevcR"
      },
      "outputs": [],
      "source": [
        "test_predictions_5 = roberta_trainer_5.predict(test_dataset_5)\n",
        "y_test_pred_5 = np.argmax(test_predictions_5.predictions, axis=1)\n",
        "y_test_true_5 = test_predictions_5.label_ids\n",
        "\n",
        "test_accuracy_5 = roberta_trainer_5.evaluate(test_dataset_5)\n",
        "print(f\"\\n Model 5 Test Accuracy: {test_accuracy_5['eval_accuracy']:.4f}\")\n",
        "test_accuracy_5 = test_accuracy_5['eval_accuracy']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6ELLrA3e2ws"
      },
      "outputs": [],
      "source": [
        "classification_report_test_5 = classification_report(y_test_true_5, y_test_pred_5, target_names=label_encoder.classes_)\n",
        "print(\"\\n Model 5 Test Classification Report:\\n\", classification_report_test_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Final%20Comparison%20Charts.png)"
      ],
      "metadata": {
        "id": "PPYPe4Fcjg5w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison Chart for Accuracy:"
      ],
      "metadata": {
        "id": "Ouy6a8uiIVSq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqCNCtbksAof"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Round and convert to percent strings\n",
        "acc_1 = f\"{round(test_accuracy_1 * 100, 1)}%\"\n",
        "acc_2 = f\"{round(test_accuracy_2 * 100, 1)}%\"\n",
        "acc_3 = f\"{round(test_accuracy_3 * 100, 1)}%\"\n",
        "acc_4 = f\"{round(test_accuracy_4 * 100, 1)}%\"\n",
        "acc_5 = f\"{round(test_accuracy_5 * 100, 1)}%\"\n",
        "\n",
        "\n",
        "# Create the DataFrame\n",
        "accuracy_df = pd.DataFrame({\n",
        "    'Model #': ['1', '2','3','4','5'],\n",
        "    'Model': ['Logistic Regression', 'Logistic Regression','BERT','BERT','RoBERTa'],\n",
        "    'Model Description': ['Avg. Word2Vec Embeddings', 'Avg. Word2Vec Embeddings','Transformer','Transformer','Transformer'],\n",
        "    'Accuracy': [acc_1, acc_2, acc_3, acc_4, acc_5],\n",
        "    'Type': ['Baseline', 'Candidate', 'Candidate','Final','Candidate',]\n",
        "})\n",
        "\n",
        "accuracy_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison chart for classification report:"
      ],
      "metadata": {
        "id": "-z0tYUB4IZCJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbuswNz35igy"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Generate reports\n",
        "report_1 = classification_report(y_test_1, preds_test_1, zero_division=0, output_dict=True)\n",
        "report_2 = classification_report(y_test_2, preds_test_2, zero_division=0, output_dict=True)\n",
        "report_3 = classification_report(y_test_true_3, y_test_pred_3, zero_division=0, output_dict=True, target_names=label_encoder.classes_)\n",
        "report_4 = classification_report(y_test_true_4, y_test_pred_4, zero_division=0, output_dict=True, target_names=label_encoder.classes_)\n",
        "report_5 = classification_report(y_test_true_5, y_test_pred_5, zero_division=0, output_dict=True, target_names=label_encoder.classes_)\n",
        "\n",
        "# Convert to DataFrames\n",
        "df1 = pd.DataFrame(report_1).T[['f1-score']].rename(columns={'f1-score': 'Model 1: Avg. Embeddings Review Only'})\n",
        "df2 = pd.DataFrame(report_2).T[['f1-score']].rename(columns={'f1-score': 'Model 2: Avg. Embeddings Review+Features'})\n",
        "df3 = pd.DataFrame(report_3).T[['f1-score']].rename(columns={'f1-score': 'Model 3: BERT Review Only'})\n",
        "df4 = pd.DataFrame(report_4).T[['f1-score']].rename(columns={'f1-score': 'Model 4: BERT Review + Features'})\n",
        "df5 = pd.DataFrame(report_5).T[['f1-score']].rename(columns={'f1-score': 'Model 5: RoBERTa Review + Features'})\n",
        "\n",
        "# Combine\n",
        "comparison_df = pd.concat([df1, df2, df3, df4, df5], axis=1)\n",
        "\n",
        "# Separate summary rows and class rows\n",
        "summary_rows = ['accuracy', 'macro avg', 'weighted avg']\n",
        "summary_df = comparison_df.loc[summary_rows]\n",
        "class_df = comparison_df.drop(index=summary_rows)\n",
        "\n",
        "# Combine summary first, then classes\n",
        "final_df = pd.concat([summary_df, class_df])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Formatted/Final Comparison Chart:"
      ],
      "metadata": {
        "id": "mGyBJZaWIe13"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09iyQfdwX834"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# Format as percentage where applicable\n",
        "def format_percent(df):\n",
        "    return df.copy().apply(lambda col: col.map(lambda x: f\"{x*100:.1f}%\" if isinstance(x, float) else x))\n",
        "\n",
        "# Split summary and class rows\n",
        "summary_rows = ['accuracy', 'macro avg', 'weighted avg']\n",
        "summary_df = format_percent(comparison_df.loc[summary_rows].reset_index())\n",
        "summary_df.columns = ['Metric'] + list(summary_df.columns[1:])\n",
        "\n",
        "class_df = format_percent(comparison_df.drop(index=summary_rows, errors='ignore').reset_index())\n",
        "class_df.columns = ['Class'] + list(class_df.columns[1:])\n",
        "\n",
        "# Colors\n",
        "body = '#fdfdfe'\n",
        "header = '#d3b4e5'\n",
        "\n",
        "def make_table(data, height):\n",
        "    fig = go.Figure(data=[go.Table(\n",
        "        header=dict(\n",
        "            values=list(data.columns),\n",
        "            fill_color=header,\n",
        "            font=dict(color='black', size=12),\n",
        "            align='center'\n",
        "        ),\n",
        "        cells=dict(\n",
        "            values=[data[col] for col in data.columns],\n",
        "            fill_color=body,\n",
        "            font=dict(color='gray', size=12),\n",
        "            align='center'\n",
        "        )\n",
        "    )])\n",
        "    fig.update_layout(width=950, height=height, margin=dict(l=10, r=10, t=20, b=10))\n",
        "    return fig\n",
        "\n",
        "# Show both tables\n",
        "make_table(summary_df, 300).show()\n",
        "make_table(class_df, 300).show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFuYjg7IPH64"
      },
      "source": [
        "#Misc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/lindsayalexandra14/ds_portfolio/raw/main/2_images/Freeze%20Library%20Requirements.png)"
      ],
      "metadata": {
        "id": "xA84pgp5jm_B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayMCo2njE7zC"
      },
      "outputs": [],
      "source": [
        "# !pip freeze > full_requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5wUxrtHFAyU"
      },
      "outputs": [],
      "source": [
        "# !pipreqs /content/ --force --savepath used_requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/lindsayalexandra14/ds_portfolio/main/1_projects/restaurant_prediction_nlp/restaurant_prediction_nlp.ipynb\n"
      ],
      "metadata": {
        "id": "XJ6dbsUr9N-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nbformat import read, write, NO_CONVERT\n",
        "\n",
        "# Load this notebook file\n",
        "notebook_path = '/content/restaurant_prediction_nlp.ipynb'  # use correct name if different\n",
        "\n",
        "with open(notebook_path, 'r', encoding='utf-8') as f:\n",
        "    nb = read(f, as_version=NO_CONVERT)\n",
        "\n",
        "# Remove any broken widget metadata\n",
        "for cell in nb.get('cells', []):\n",
        "    if 'metadata' in cell and 'widget' in cell['metadata']:\n",
        "        del cell['metadata']['widget']\n",
        "    if 'metadata' in cell and 'widget_state' in cell['metadata']:\n",
        "        del cell['metadata']['widget_state']\n",
        "\n",
        "# Save cleaned notebook to a new file\n",
        "clean_path = 'restaurant_prediction_nlp_final.ipynb'\n",
        "\n",
        "with open(clean_path, 'w', encoding='utf-8') as f:\n",
        "    write(nb, f)\n",
        "\n",
        "print(\"Cleaned notebook saved as:\", clean_path)\n"
      ],
      "metadata": {
        "id": "zMA3-efk7yYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to python restaurant_prediction_nlp_final.ipynb"
      ],
      "metadata": {
        "id": "fSdf4xyC9iBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download(\"restaurant_prediction_nlp_final.py\")"
      ],
      "metadata": {
        "id": "-GEjTRRq9tma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install texlive-xetex texlive-fonts-recommended texlive-plain-generic -y\n"
      ],
      "metadata": {
        "id": "dsmQGVRA9WhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y pandoc"
      ],
      "metadata": {
        "id": "oAj3EGCR_GUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to pdf restaurant_prediction_nlp_final.ipynb"
      ],
      "metadata": {
        "id": "Wry7LXLc-CbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"restaurant_prediction_nlp_final.pdf\")"
      ],
      "metadata": {
        "id": "b1HQiqBR-MNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to html restaurant_prediction_nlp_final.ipynb"
      ],
      "metadata": {
        "id": "kwAL0cix-egT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"restaurant_prediction_nlp_final.html\")"
      ],
      "metadata": {
        "id": "j-r4Y9fP-kGU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}